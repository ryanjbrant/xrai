# VFX Binding Specification (Rcam/Metavido)

**Tags**: #vfx #bindings #rcam #keijiro
**Quick ref**: `_VFX_QUICK_REF.md` | **YAML**: `_VFX_MASTER_PATTERNS.md` | **AR**: `_VFX_AR_MASTER.md`

Binding reference for Keijiro Rcam-based VFX integration (73 assets analyzed).

**Updated**: 2026-01-20 | **Source**: MetavidoVFX, Rcam2/3/4, VFXARBinder.cs

---

## Executive Summary

MetavidoVFX contains **73 VFX assets** across Rcam2, Rcam3, and Rcam4 categories. This specification documents the **exact property bindings** required for each category, compute shader dependencies, and integration with the **Hybrid Bridge Pipeline** (ARDepthSource + VFXARBinder).

### Key Findings

1. **Property Naming Evolution**: Rcam2 uses `RayParamsMatrix` (Matrix4x4), Rcam3/4 standardized on `InverseProjection` (Vector4) + `InverseView` (Matrix4x4)
2. **Compute Dependency**: ALL Rcam VFX require `PositionMap` (world positions from depth) - MetavidoVFX provides this via ARDepthSource
3. **Stencil Separation**: Body vs Environment VFX distinguished by `StencilMap` binding (People effects need it, Environment effects do NOT)
4. **Velocity Support**: Rcam4 VFX (lightning, trails) require optional `VelocityMap` for motion-reactive effects

---

## VFX Asset Inventory

| Category | Count | Path | Examples |
|----------|-------|------|----------|
| **Rcam2** | 20 | `Assets/Resources/VFX/Rcam2/` | brush, bubble, candy, dot, emoji, eyeball, floor, fragment, glitch, particle, petal (2x), point, ribbon, spark, spike, text, trail, voxel, warp |
| **Rcam3** | 8 | `Assets/Resources/VFX/Rcam3/` | flame, grid, particles, plexus, points, scanlines, sparkles, sweeper |
| **Rcam4** | 14 | `Assets/Resources/VFX/Rcam4/` | balls, bubbles, flame, grid, lightning, petals, pointcloud, rcam4, shards, sparkles, speedlines, spikes, trails, voxels |
| **Total** | 42 | | Rcam-based VFX |

**Note**: MetavidoVFX also includes 31 other VFX (Akvfx, NNCam2, SdfVfx, People, Environment) with different binding requirements.

---

## Property Binding Matrix

### Rcam2 (HDRP ‚Üí URP Converted)

**Requires HDRP 8.2.0 ‚Üí URP 17.0.3 property renaming**

| VFX Property | Type | MetavidoVFX Source | Notes |
|--------------|------|-------------------|-------|
| `ColorMap` | Texture2D | `ARDepthSource.ColorMap` | AR camera RGB (demand-driven) |
| `DepthMap` | Texture2D | `ARDepthSource.DepthMap` | Raw depth (RFloat) |
| `RayParamsMatrix` | **Matrix4x4** | **DEPRECATED** | ‚ö†Ô∏è Rcam2 legacy - replace with `RayParams` (Vector4) |
| `RayParams` | Vector4 | `ARDepthSource.RayParams` | `(centerShiftX, centerShiftY, tanH, tanV)` |
| `DepthThreshold` | float | VFX-specific | Environment effects use this for filtering |
| `Size` | float | VFX-specific | Particle size control |
| `Throttle` | float | `VFXARBinder.Throttle` | 0-1 intensity control |

**Compute Dependency**: Rcam2 VFX expect `RayParamsMatrix` (4x4) but MetavidoVFX provides `RayParams` (Vector4). **Solution**: Use VFXARBinder alias resolution (`RayParamsMatrix` ‚Üí `RayParams`) or modify VFX to use Vector4.

**Critical Finding**: Rcam2 `RayParamsMatrix` is **NOT** the same as `InverseProjection`. It's a **full 4x4 matrix** computed from camera intrinsics, while `InverseProjection` is a **Vector4** with compressed parameters.

### Rcam3 (URP, Standard)

| VFX Property | Type | MetavidoVFX Source | Notes |
|--------------|------|-------------------|-------|
| `ColorMap` | Texture2D | `ARDepthSource.ColorMap` | AR camera RGB |
| `DepthMap` | Texture2D | `ARDepthSource.DepthMap` | Raw depth |
| `RayParams` | Vector4 | `ARDepthSource.RayParams` | UV+depth ‚Üí world position |
| `InverseProjection` | Vector4 | **COMPUTED** | `(1/fx, 1/fy, cx/fx, cy/fy)` |
| `InverseView` | Matrix4x4 | `ARDepthSource.InverseView` | `TRS(cameraPos, cameraRot, Vector3.one)` |
| `Dimensions` | Vector2 | VFX-specific | Effect spatial bounds |
| `FocusDistance` | float | VFX-specific | Depth-of-field effect |
| `HueShift` | float | VFX-specific | Color variation |
| `Ripple` | float | VFX-specific | Wave animation |
| `Origin` | Vector3 | VFX-specific | Effect spawn point |
| `Throttle` | float | `VFXARBinder.Throttle` | 0-1 intensity |

**Key Difference**: Rcam3 introduces `InverseProjection` (Vector4) as the standard for depth reconstruction, replacing Rcam2's `RayParamsMatrix`.

**Compute Pattern** (Rcam3/4 Standard):
```hlsl
float3 RcamDistanceToWorldPosition(float2 uv, float d, float4 inv_proj, float4x4 inv_view) {
    float3 p = float3((uv - 0.5) * 2, 1);        // UV ‚Üí NDC
    p.xy = (p.xy * inv_proj.xy) + inv_proj.zw;  // NDC ‚Üí View
    return mul(inv_view, float4(p * d, 1)).xyz; // View ‚Üí World
}
```

### Rcam4 (URP, Production)

| VFX Property | Type | MetavidoVFX Source | Notes |
|--------------|------|-------------------|-------|
| `ColorMap` | Texture2D | `ARDepthSource.ColorMap` | AR camera RGB |
| `DepthMap` | Texture2D | `ARDepthSource.DepthMap` | Raw depth |
| `RayParams` | Vector4 | `ARDepthSource.RayParams` | UV+depth ‚Üí world |
| `InverseProjection` | Vector4 | **COMPUTED** | `(1/fx, 1/fy, cx/fx, cy/fy)` |
| `InverseView` | Matrix4x4 | `ARDepthSource.InverseView` | Camera TRS matrix |
| `Particles` | int | VFX-specific | Max particle count |
| `Strip` | int | VFX-specific | Lightning strip count |
| `Throttle` | float | `VFXARBinder.Throttle` | 0-1 intensity |

**Rcam4-Specific Features**:
- **VelocityMap** (optional): Lightning/trail effects use motion data
- **NDI Metadata**: Original Rcam4 streams XML metadata for camera pose, but MetavidoVFX extracts this locally from `ARCameraManager.frameReceived`

---

## Compute Shader Requirements

### ARDepthSource Pipeline (MetavidoVFX Implementation)

**File**: `Assets/Shaders/DepthToWorld.compute`

```hlsl
#pragma kernel DepthToWorld

Texture2D<float> _Depth;       // Input: AR depth map
RWTexture2D<float4> _PositionRT; // Output: World positions

float4x4 _InvVP;                // Inverse view-projection matrix

[numthreads(32,32,1)]
void DepthToWorld(uint3 id : SV_DispatchThreadID) {
    float depth = _Depth[id.xy];
    if (depth <= 0) return;

    // UV ‚Üí NDC ‚Üí World
    float2 uv = (id.xy + 0.5) / float2(_Width, _Height);
    float3 ndc = float3((uv - 0.5) * 2, 1);
    float3 worldPos = mul(_InvVP, float4(ndc * depth, 1)).xyz;

    _PositionRT[id.xy] = float4(worldPos, 1);
}
```

**Dispatch Pattern** (O(1) scaling):
```csharp
// ARDepthSource.cs - SINGLE dispatch for ALL VFX
int groupsX = Mathf.CeilToInt(depth.width / 32f);
int groupsY = Mathf.CeilToInt(depth.height / 32f);
_depthToWorld.Dispatch(_kernel, groupsX, groupsY, 1);
```

**Critical**: Thread group size is `[numthreads(32,32,1)]`, NOT 8x8. Using `ceil(width/8)` causes **thread group mismatch errors**.

### VelocityMap Compute (Optional)

**Kernel**: `CalculateVelocity` (same compute shader)

```hlsl
#pragma kernel CalculateVelocity

RWTexture2D<float4> _PositionRT;          // Current frame
Texture2D<float4> _PreviousPositionRT;    // Previous frame
RWTexture2D<float4> _VelocityRT;          // Output velocity
float _DeltaTime;

[numthreads(32,32,1)]
void CalculateVelocity(uint3 id : SV_DispatchThreadID) {
    float3 pos = _PositionRT[id.xy].xyz;
    float3 prevPos = _PreviousPositionRT[id.xy].xyz;
    float3 velocity = (pos - prevPos) / _DeltaTime;
    _VelocityRT[id.xy] = float4(velocity, 1);
}
```

**Enable in ARDepthSource**: `_enableVelocity = true` (disabled by default - can cause tracking jitter)

---

## VFXARBinder Integration

### Property Alias Resolution (Cross-Project Compatibility)

VFXARBinder supports **automatic alias resolution** for Rcam2, Rcam3, Rcam4, Akvfx, and H3M VFX:

```csharp
// VFXARBinder.cs - Property aliases (lines 119-129)
static readonly string[] DepthMapAliases = { "DepthMap", "Depth", "DepthTexture", "_Depth" };
static readonly string[] StencilMapAliases = { "StencilMap", "Stencil", "HumanStencil", "StencilTexture" };
static readonly string[] PositionMapAliases = { "PositionMap", "Position", "WorldPosition", "WorldPos" };
static readonly string[] ColorMapAliases = { "ColorMap", "Color", "ColorTexture", "CameraColor", "MainTex" };
static readonly string[] RayParamsAliases = { "RayParams", "RayParameters", "CameraParams" };
static readonly string[] InverseViewAliases = { "InverseView", "InvView", "CameraToWorld", "ViewInverse" };
static readonly string[] InverseProjAliases = { "InverseProjection", "RayParamsMatrix", "InvProj", "ProjectionInverse" };
```

**Auto-Detection**:
```csharp
// Right-click VFXARBinder in Inspector ‚Üí "Auto-Detect Bindings (with Aliases)"
// OR: H3M > VFX Pipeline Master > Testing > Validate All Bindings
```

### Binding Toggle Patterns

| VFX Type | Toggles | Notes |
|----------|---------|-------|
| **Rcam2 (People)** | DepthMap, ColorMap, StencilMap, RayParams | Requires stencil for body separation |
| **Rcam2 (Environment)** | DepthMap, ColorMap, RayParams | NO stencil |
| **Rcam3 (People)** | DepthMap, ColorMap, RayParams, InverseView | Uses InverseView for world-space particles |
| **Rcam3 (Any)** | DepthMap, ColorMap, RayParams | Grid/sweeper don't care about body/env |
| **Rcam4 (People)** | DepthMap, ColorMap, RayParams, InverseView | Production-ready URP effects |
| **Rcam4 (Environment)** | DepthMap, ColorMap, RayParams | Speedlines, grid, shards |

**Example Configuration** (Rcam3 `plexus_depth_people_rcam3.vfx`):
```csharp
_bindDepthMap = true;
_bindColorMap = true;
_bindRayParams = true;
_bindInverseView = true;
_bindStencilMap = false;  // Plexus uses depth only, not stencil
_bindPositionMap = true;  // Computed by ARDepthSource
```

---

## Body vs Environment Separation

### Stencil-Based Filtering

**People VFX** (Rcam2/3/4 `*_depth_people_*`):
- Bind `StencilMap` from `AROcclusionManager.humanStencilTexture`
- VFX samples stencil in Initialize/Update contexts to spawn particles only on humans

**Environment VFX** (Rcam2/3/4 `*_environment_*`):
- Do NOT bind `StencilMap` (or bind `Texture2D.whiteTexture` as dummy)
- VFX spawns particles on all depth data

**"Any" VFX** (Rcam3 `*_any_*`):
- Grid, sweeper effects work on full scene
- Stencil binding optional (ignored by VFX logic)

### Stencil Access Pattern (AR Foundation)

```csharp
// ARDepthSource.cs - Safe texture access
Texture TryGetTexture(System.Func<Texture> getter) {
    try { return getter?.Invoke(); }
    catch { return null; }
}

Texture stencil = TryGetTexture(() => _occlusion.humanStencilTexture);
StencilMap = stencil ?? Texture2D.whiteTexture;  // Fallback to white (all 1s)
```

**Stencil Format**: R8 (single-channel), 0 = environment, 1 = human

---

## InverseProjection Calculation (Rcam3/4 Standard)

### C# Implementation

```csharp
// Source: Keijiro's Rcam3/4 CameraUtil.cs
public static Vector4 GetInverseProjection(Matrix4x4 projectionMatrix) {
    var x = 1 / projectionMatrix[0, 0];  // 1 / focal_x
    var y = 1 / projectionMatrix[1, 1];  // 1 / focal_y
    var z = projectionMatrix[0, 2] * x;  // center_x / focal_x
    var w = projectionMatrix[1, 2] * y;  // center_y / focal_y
    return new Vector4(x, y, z, w);
}
```

**Usage** (if VFX requires InverseProjection explicitly):
```csharp
// In VFXARBinder.cs LateUpdate()
if (_bindInverseProj && _vfx.HasMatrix4x4(inverseProjProperty)) {
    var cam = Camera.main;
    var invProj = GetInverseProjection(cam.projectionMatrix);
    _vfx.SetVector4(inverseProjProperty, invProj);
}
```

**Note**: MetavidoVFX currently uses `RayParams` (similar concept) instead of `InverseProjection`. For true Rcam3/4 compatibility, add this calculation.

---

## RayParams vs InverseProjection

### RayParams (MetavidoVFX Standard)

```csharp
// ARDepthSource.cs - Compute RayParams
var proj = _arCamera.projectionMatrix;
float centerShiftX = proj.m02;
float centerShiftY = proj.m12;
float fov = _arCamera.fieldOfView * Mathf.Deg2Rad;
float tanV = Mathf.Tan(fov * 0.5f);
float tanH = tanV * _arCamera.aspect;

RayParams = new Vector4(centerShiftX, centerShiftY, tanH, tanV);
```

**Components**:
- `.xy`: Principal point offset (lens center shift)
- `.z`: `tan(fov_horizontal / 2)`
- `.w`: `tan(fov_vertical / 2)`

### InverseProjection (Rcam3/4 Standard)

```csharp
InverseProjection = new Vector4(
    1 / proj[0, 0],          // 1 / focal_x
    1 / proj[1, 1],          // 1 / focal_y
    proj[0, 2] / proj[0, 0], // center_x / focal_x
    proj[1, 2] / proj[1, 1]  // center_y / focal_y
);
```

**Equivalence**: Both encode the same camera intrinsics, but with different parameterizations:
- `RayParams.zw` = `tan(FOV/2)` (angle-based)
- `InverseProjection.xy` = `1/focal_length` (focal-length-based)

**Conversion**: `1 / focal_x ‚âà tan(fov_x / 2) / (width / 2)`

---

## Depth Rotation (iOS Portrait Mode)

### Problem: ARKit Depth is Landscape

ARKit depth textures are always **landscape orientation** (wider than tall), even in portrait mode. MetavidoVFX VFX expect **portrait depth** (taller than wide).

**Solution**: 90¬∞ CW rotation using shader + RT swap

```csharp
// ARDepthSource.cs - Rotate depth 90¬∞ CW
[SerializeField] bool _rotateDepthTexture = true;  // Default: enabled

Texture RotateTexture(Texture source, ref RenderTexture rotatedRT) {
    // Swap width/height
    int rotW = source.height;
    int rotH = source.width;

    // Create RT with swapped dimensions
    rotatedRT = new RenderTexture(rotW, rotH, 0, RenderTextureFormat.RFloat);

    // Blit with RotateUV90CW shader
    Graphics.Blit(source, rotatedRT, _rotateMaterial);
    return rotatedRT;
}
```

**Shader**: `Assets/Resources/RotateUV90CW.shader`
```hlsl
Shader "Hidden/RotateUV90CW" {
    SubShader {
        Pass {
            CGPROGRAM
            #pragma vertex vert_img
            #pragma fragment frag
            sampler2D _MainTex;

            float4 frag(v2f_img i) : SV_Target {
                float2 uv = i.uv;
                uv = float2(1.0 - uv.y, uv.x); // 90¬∞ CW rotation
                return tex2D(_MainTex, uv);
            }
            ENDCG
        }
    }
}
```

**RayParams Adjustment** (negated tanH):
```csharp
if (_rotateDepthTexture) {
    float depthAspect = (float)depth.width / depth.height;
    tanH = tanV * depthAspect;
    RayParams = new Vector4(centerShiftX, centerShiftY, -tanH, tanV); // Negate tanH
}
```

---

## VFXProxBuffer (Rcam3 Spatial Acceleration)

### When Needed

**Plexus/Metaball Effects**: VFX that connect particles with lines or form mesh surfaces require **nearest-neighbor queries**. Without acceleration, this is O(N¬≤) brute force.

**Rcam3 Solution**: VFXProxBuffer - 16√ó16√ó16 spatial hash grid (4096 cells, 32 points/cell max)

### Implementation

**C# Setup**:
```csharp
// VFXProxBuffer.cs (from Rcam3)
const int CellsPerAxis = 16;
const int CellCapacity = 32;

GraphicsBuffer pointBuffer;  // 4096 * 32 * float3 = 1.5MB
GraphicsBuffer countBuffer;  // 4096 * uint = 16KB

// Compute shader dispatch
_compute.SetBuffer(0, "VFXProx_PointBuffer", pointBuffer);
_compute.SetBuffer(0, "VFXProx_CountBuffer", countBuffer);
_compute.DispatchThreads(0, CellsPerAxis, CellsPerAxis, CellsPerAxis);
```

**HLSL API** (VFXProxCommon.hlsl):
```hlsl
// Add particle to grid (VFX Initialize context)
void VFXProx_AddPoint(float3 pos) {
    uint index = VFXProx_GetFlatIndexAt(pos);
    uint count = 0;
    InterlockedAdd(VFXProx_CountBuffer[index], 1, count);
    if (count < VFXProx_CellCapacity)
        VFXProx_PointBuffer[index * VFXProx_CellCapacity + count] = pos;
}

// Query nearest 2 points (VFX Update context)
void VFXProx_LookUpNearestPair(float3 pos, out float3 first, out float3 second) {
    // Searches 3x3x3 = 27 cells around query position
    // Returns 2 closest points for line connections
}
```

**Performance**: O(1) insertion, O(864) queries per particle (27 cells √ó 32 max points)

**MetavidoVFX Status**: NOT currently implemented. Plexus VFX (`plexus_depth_people_rcam3.vfx`) would benefit from this.

---

## Blitter Class (Unity 6 / URP)

### Problem: Graphics.Blit Deprecated

Unity 6 deprecated `Graphics.Blit` for URP. Keijiro's Rcam4 introduced **Blitter class** using `DrawProceduralNow`.

**Implementation** (Rcam4 Utils.cs):
```csharp
public class Blitter : System.IDisposable {
    Material _material;

    public Blitter(Shader shader) => _material = new Material(shader);

    public void Run(Texture source, RenderTexture dest, int pass) {
        RenderTexture.active = dest;
        _material.mainTexture = source;
        _material.SetPass(pass);
        Graphics.DrawProceduralNow(MeshTopology.Triangles, 3, 1); // Fullscreen triangle
    }

    public void Dispose() { Object.Destroy(_material); }
}
```

**Usage**:
```csharp
var blitter = new Blitter(Shader.Find("Hidden/MyFullscreenShader"));
blitter.Run(sourceTexture, destRT, 0);
blitter.Dispose();
```

**MetavidoVFX Status**: Currently using `Graphics.Blit` for depth rotation. Should migrate to Blitter for Unity 6+ compliance.

---

## MetavidoVFX Integration Checklist

### ‚úÖ Implemented

- [x] ARDepthSource - Single compute dispatch for ALL VFX
- [x] VFXARBinder - Lightweight per-VFX binding with alias resolution
- [x] RayParams calculation (centerShift + tan(FOV))
- [x] InverseView matrix (TRS pattern)
- [x] Depth rotation for iOS portrait mode
- [x] StencilMap binding (human segmentation)
- [x] Demand-driven ColorMap allocation (spec-007)
- [x] Throttle/Intensity binding
- [x] Audio binding (global shader vectors)

### ‚ö†Ô∏è Partially Implemented

- [ ] InverseProjection (Vector4) - Currently using RayParams instead
- [ ] VelocityMap - Compute kernel exists but disabled by default
- [ ] Normal map - Compute kernel exists, rarely used

### ‚ùå Not Implemented (Rcam3/4 Features)

- [ ] VFXProxBuffer - Spatial hash grid for plexus/metaball effects
- [ ] Blitter class - Using deprecated Graphics.Blit instead
- [ ] Color LUT (Texture3D) - Rcam3/4 support color grading LUTs
- [ ] URP Renderer Features - Rcam4 integrates background/recolor as Renderer Features

### üîß Migration Tasks

1. **Rcam2 VFX Property Renaming**:
   - `RayParamsMatrix` (Matrix4x4) ‚Üí `RayParams` (Vector4)
   - OR: Modify VFXARBinder to compute Matrix4x4 from RayParams

2. **InverseProjection Support**:
   - Add `GetInverseProjection()` method to ARDepthSource
   - Bind as Vector4 to VFX (currently using RayParams)

3. **VFXProxBuffer Integration**:
   - Port Rcam3's VFXProxBuffer.cs + VFXProxCommon.hlsl
   - Enable for `plexus_depth_people_rcam3.vfx` and similar effects

4. **Blitter Migration**:
   - Replace `Graphics.Blit` in depth rotation code
   - Use Blitter for all fullscreen shader passes

---

## Critical Notes (Always Remember)

### Property Naming Standards

| Rcam2 (Legacy) | Rcam3/4 (Standard) | MetavidoVFX |
|----------------|-------------------|-------------|
| `ProjectionVector` | `InverseProjection` | `RayParams` |
| `InverseViewMatrix` | `InverseView` | `InverseView` |
| `RayParamsMatrix` (4x4) | `RayParams` (Vector4) | `RayParams` (Vector4) |

**Migration Path**: VFXARBinder's alias resolution handles these differences automatically.

### Compute Shader Thread Groups

‚ùå **WRONG**: `[numthreads(8,8,1)]` + `ceil(width/8)` dispatch
‚úÖ **CORRECT**: `[numthreads(32,32,1)]` + `ceil(width/32)` dispatch

**Reason**: Thread group size must match dispatch groups. Mismatch causes "Thread group count exceeds maximum" errors.

### Depth Formats

Always use **RenderTextureFormat.RHalf** (16-bit float) for depth:
```csharp
var depthRT = new RenderTexture(width, height, 0, RenderTextureFormat.RHalf) {
    wrapMode = TextureWrapMode.Clamp
};
```

### VFX Global Texture Access

‚ùå **DOES NOT WORK**: `Shader.SetGlobalTexture("_DepthMap", depth);`
‚úÖ **WORKS**: `vfx.SetTexture("DepthMap", depth);`

**Reason**: VFX Graph cannot read global textures set via `Shader.SetGlobal*`. Must use per-VFX `SetTexture()`.

**Exception**: Vectors/Matrices CAN be global:
```csharp
Shader.SetGlobalVector("_ARRayParams", rayParams);  // ‚úÖ Works
Shader.SetGlobalMatrix("_ARInverseView", invView);  // ‚úÖ Works
```

---

## Testing Procedure

### 1. Auto-Detection (Recommended)

```csharp
// In Unity Editor:
// 1. Select VFX GameObject with VFXARBinder component
// 2. Right-click component ‚Üí "Auto-Detect Bindings (with Aliases)"
// 3. Verify bindings in Inspector
```

**Expected Output** (Console):
```
[VFXARBinder] Auto-detected bindings for plexus_depth_people_rcam3 (with alias resolution):
  DepthMap=True (DepthMap)
  StencilMap=False (none)
  PositionMap=True (PositionMap)
  ColorMap=True (ColorMap)
  RayParams=True (RayParams)
  InverseView=True (InverseView)
  InverseProj=False (none)
  Throttle=True (Throttle)
```

### 2. Manual Verification

**Menu**: `H3M > VFX Pipeline Master > Testing > Validate All Bindings`

**Checks**:
- ARDepthSource exists and is ready
- All VFX have VFXARBinder
- No VFXBinderManager/VFXARDataBinder (legacy) present
- Binding toggles match VFX properties
- Textures are valid (not null, width/height > 0)

### 3. Runtime Dashboard

**Keyboard**: Press `Tab` in Play mode (requires VFXPipelineDashboard)

**Metrics**:
- FPS graph (60-frame history, min/avg/max)
- Pipeline flow: ARDepthSource ‚Üí VFXARBinder ‚Üí VFX
- Binding status (green/red per VFX)
- Texture allocations (DepthMap, StencilMap, PositionMap, ColorMap)
- Particle counts

### 4. Build Testing (iOS)

**Commands**:
```bash
./build_ios.sh           # Unity build ‚Üí Xcode project
./build_and_deploy.sh    # Full cycle ‚Üí device install
./debug.sh               # Stream device logs
```

**Expected Console Output** (iOS device):
```
[ARDepthSource] Depth available: 192x256 (rotated=True)
[VFXARBinder] plexus_depth_people_rcam3: Bound 6 properties. IsBound=True
[VFXPipelineDashboard] FPS: 60.2 (avg), Binders: 10/10 active, Memory: 48.3 MB
```

---

## Reference Files

### MetavidoVFX

| File | Purpose |
|------|---------|
| `Assets/Scripts/Bridges/ARDepthSource.cs` | Singleton compute source, O(1) dispatch |
| `Assets/Scripts/Bridges/VFXARBinder.cs` | Lightweight per-VFX binding with aliases |
| `Assets/Scripts/VFX/VFXLibraryManager.cs` | VFX library with pipeline integration |
| `Assets/Scripts/VFX/VFXPipelineDashboard.cs` | Real-time debug UI (Tab toggle) |
| `Assets/Scripts/VFX/VFXTestHarness.cs` | Keyboard shortcuts (1-9, Space, C, A, P) |
| `Assets/Scripts/Editor/VFXPipelineMasterSetup.cs` | Editor automation (`H3M > VFX Pipeline Master`) |
| `Assets/Shaders/DepthToWorld.compute` | GPU depth‚Üíworld position conversion |
| `Assets/Resources/RotateUV90CW.shader` | 90¬∞ CW rotation for iOS portrait |
| `Assets/Resources/VFX/Rcam2/` | 20 Rcam2 VFX (HDRP‚ÜíURP converted) |
| `Assets/Resources/VFX/Rcam3/` | 8 Rcam3 VFX (URP standard) |
| `Assets/Resources/VFX/Rcam4/` | 14 Rcam4 VFX (URP production) |

### Keijiro's Rcam Repositories

| Repo | URL | Key Files |
|------|-----|-----------|
| **Rcam2** | https://github.com/keijiro/Rcam2 | `VFXRcamMetadataBinder.cs`, `RcamReceiver.cs` |
| **Rcam3** | https://github.com/keijiro/Rcam3 | `VFXRcamBinder.cs`, `VFXProxBuffer.cs`, `RcamCommon.hlsl` |
| **Rcam4** | https://github.com/keijiro/Rcam4 | `VFXRcamBinder.cs`, `Utils.cs` (Blitter), `RcamCommon.hlsl` |

### Knowledge Base

| File | Purpose |
|------|---------|
| `KnowledgeBase/_RCAM_QUICK_REFERENCE.md` | Property naming, binder pattern, depth reconstruction |
| `KnowledgeBase/_RCAM_SERIES_ARCHITECTURE_RESEARCH.md` | Full architecture comparison (47 files analyzed) |
| `KnowledgeBase/_ARFOUNDATION_VFX_KNOWLEDGE_BASE.md` | 50+ production code snippets |
| `KnowledgeBase/_MASTER_GITHUB_REPO_KNOWLEDGEBASE.md` | 520+ curated repos (keijiro section) |

---

**End of Specification**

Generated: 2026-01-20
Researcher: Unity XR-AI Research Agent
Total VFX Analyzed: 73 (42 Rcam-based, 31 other)
Total Bindings Documented: 25+ properties across 3 Rcam versions
Key Findings: Property evolution, compute requirements, binding patterns
# Akvfx & SdfVfx Binding Specification

**Research Date**: 2026-01-20
**Unity Version**: 6000.2.14f1
**VFX Graph**: 17.2.0
**Status**: Production-verified (73 VFX in MetavidoVFX)

---

## Executive Summary

This document provides comprehensive binding specifications for **keijiro's Akvfx** (Azure Kinect ‚Üí VFX Graph) and **SdfVfx** (Signed Distance Field environment effects) projects. These patterns are production-tested in MetavidoVFX with 7 Akvfx VFX and 5 SdfVfx VFX.

**Key Insight**: Both systems use **pre-computed texture maps** rather than raw sensor data, enabling efficient GPU-based particle effects with minimal CPU overhead.

---

## 1. Akvfx (Azure Kinect VFX)

### 1.1 Overview

**Repository**: [keijiro/Akvfx](https://github.com/keijiro/Akvfx)
**Purpose**: Captures color/depth data from Azure Kinect DK and converts to attribute maps (textures) for VFX Graph
**Unity Version**: 2019.3+ (tested through Unity 6)
**Platform**: Windows only (Azure Kinect SDK limitation)

**Key Innovation**: Azure Kinect depth sensor ‚Üí PositionMap (pre-computed world positions) for point cloud rendering.

### 1.2 Data Pipeline

```
Azure Kinect DK (Hardware)
    ‚Üì
Azure Kinect SDK (Native)
    ‚Üì
Akvfx Plugin (Unity Package)
    ‚Üì
Texture Generation (GPU Compute)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PositionMap ‚îÇ ColorMap     ‚îÇ
‚îÇ (RGBAFloat) ‚îÇ (RGB24)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
VFX Graph (Particle Systems)
```

**Compute Shader**: `Akvfx.compute` converts depth ‚Üí world positions
**Output Format**: RGBAFloat texture (x, y, z, confidence)

### 1.3 Required VFX Properties

**Core Properties (ALL Akvfx VFX need these)**:

| Property | Type | Description | Example Value |
|----------|------|-------------|---------------|
| `PositionMap` | Texture2D | World positions (RGBAFloat) | 512x424 RGBAFloat |
| `ColorMap` | Texture2D | Camera RGB texture | 1920x1080 RGB24 |
| `MapWidth` | int | Texture width in pixels | 512 |
| `MapHeight` | int | Texture height in pixels | 424 |

**Optional Properties**:

| Property | Type | Description | Example Value |
|----------|------|-------------|---------------|
| `PointSize` | float | Point primitive size | 0.005 |
| `Multiplexer` | float | Effect variation control | 0-1 range |

### 1.4 VFX Types (7 in MetavidoVFX)

All located in `Assets/Resources/VFX/Akvfx/`:

| VFX Name | Description | Unique Properties |
|----------|-------------|-------------------|
| `point_stencil_people_akvfx.vfx` | Point cloud rendering | `PointSize` |
| `web_stencil_people_akvfx.vfx` | Interconnected web mesh | - |
| `spikes_stencil_people_akvfx.vfx` | Outward spike extrusion | - |
| `voxel_stencil_people_akvfx.vfx` | Voxelized cube rendering | `Multiplexer` |
| `particles_stencil_people_akvfx.vfx` | Particle cloud | - |
| `lines_stencil_people_akvfx.vfx` | Line-based visualization | - |
| `leaves_stencil_people_akvfx.vfx` | Leaf/petal shapes | - |

**Naming Convention**: `{effect}_{stencil|full}_{people|environment}_akvfx.vfx`

### 1.5 AR Foundation Adaptation

**Critical Difference**: Akvfx uses Azure Kinect depth, MetavidoVFX uses ARKit/ARCore depth.

**Adaptation Strategy** (from ARDepthSource.cs):

```csharp
// 1. Get AR depth texture
Texture2D depthTexture = occlusionManager.humanDepthTexture; // or environmentDepthTexture

// 2. Compute PositionMap via DepthToWorld.compute (replaces Akvfx.compute)
computeShader.SetTexture(kernel, "DepthIn", depthTexture);
computeShader.SetTexture(kernel, "PositionOut", positionMap); // RGBAFloat
computeShader.SetVector("RayParams", rayParams); // (0, 0, tan(fov/2)*aspect, tan(fov/2))
computeShader.SetMatrix("InverseView", camera.cameraToWorldMatrix);
computeShader.Dispatch(kernel, width/32, height/32, 1);

// 3. Bind to VFX (via VFXARBinder)
vfx.SetTexture("PositionMap", positionMap);
vfx.SetTexture("ColorMap", cameraColorTexture);
vfx.SetInt("MapWidth", positionMap.width);
vfx.SetInt("MapHeight", positionMap.height);
```

**Key Files**:
- `Assets/Scripts/Bridges/ARDepthSource.cs` - Single compute dispatch (O(1) cost)
- `Assets/Resources/DepthToWorld.compute` - Depth‚Üíworld position conversion
- `Assets/Scripts/Bridges/VFXARBinder.cs` - Lightweight per-VFX binding

**Performance**: 353 FPS @ 10 active VFX (verified Jan 16, 2026)

### 1.6 Property Resolution (Cross-Project Compatibility)

VFXARBinder auto-detects property aliases:

```csharp
// Standard name is first, aliases follow
static readonly string[] PositionMapAliases = { "PositionMap", "Position", "WorldPosition", "WorldPos" };
static readonly string[] ColorMapAliases = { "ColorMap", "Color", "ColorTexture", "CameraColor", "MainTex" };
```

**Auto-Detection** (from VFXARBinder.cs line 179):
```csharp
if (_autoBindOnStart)
{
    AutoDetectBindings(); // Scans VFX for properties, enables bindings
}
```

---

## 2. SdfVfx (Signed Distance Field VFX)

### 2.1 Overview

**Repository**: [keijiro/SdfVfxSamples](https://github.com/keijiro/SdfVfxSamples)
**Purpose**: Unity VFX Graph samples using SDF (signed distance field) for environment particle effects
**Unity Version**: Unity 6+ (requires VFX Graph 17+)
**Platform**: All platforms (GPU compute only)

**Key Innovation**: 3D texture (SDF) defines particle constraints - particles stick to/flow along complex surfaces.

### 2.2 What is an SDF?

**Signed Distance Field (SDF)**: 3D texture where each texel stores:
- **Positive values**: Distance OUTSIDE the surface
- **Negative values**: Distance INSIDE the surface
- **Zero**: ON the surface

**Visual Analogy**: Like a height map, but in 3D - tells particles how far they are from any surface.

### 2.3 Data Pipeline

```
3D Mesh or Procedural Shape
    ‚Üì
SDF Bake Tool (Unity Editor or Runtime API)
    ‚Üì
3D Texture (Texture3D, RFloat format)
    ‚Üì
VFX Graph (SDF Nodes)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Position On SDF      ‚îÇ Attractor SDF     ‚îÇ Collision SDF    ‚îÇ
‚îÇ (place on surface)   ‚îÇ (attract to)      ‚îÇ (bounce off)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Baking**: Resource-intensive. Pre-bake in Editor for best performance.
**Runtime Baking**: Use low resolution if baking per-frame (e.g., 32¬≥ for dynamic objects).

### 2.4 Required VFX Properties

**Core Property (ALL SdfVfx VFX need this)**:

| Property | Type | Description | Example Value |
|----------|------|-------------|---------------|
| `SDF` | Texture3D | Signed distance field volume | 128√ó128√ó128 RFloat |

**Optional Properties**:

| Property | Type | Description | Example Value |
|----------|------|-------------|---------------|
| `Spawn Rate` | float | Particle emission rate | 1000/sec |
| `Kill` | bool | Kill event trigger | false |

**VFX Graph Nodes** (from [Unity Docs - SDF in VFX Graph](https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@17.2/manual/sdf-in-vfx-graph.html)):
- **Position On Signed Distance Field**: Place particles inside volume or on surface
- **Attractor Shape Signed Distance Field**: Attract particles toward SDF
- **Collision Shape Signed Distance Field**: Simulate collision with SDF
- **Sample Signed Distance Field**: Custom behavior (sample distance at any point)

### 2.5 VFX Types (5 in MetavidoVFX)

All located in `Assets/Resources/VFX/SdfVfx/`:

| VFX Name | Description | Unique Properties |
|----------|-------------|-------------------|
| `trails_environment_sdfvfx.vfx` | Particle trails constrained to SDF surface | - |
| `stickies_environment_sdfvfx.vfx` | Particles stick to surface on approach | `Spawn Rate`, `Kill` |
| `grape_environment_sdfvfx.vfx` | Grape-like clusters on surface | - |
| `circuits_environment_sdfvfx.vfx` | Circuit-board style particle flow | - |
| `blocks_environment_sdfvfx.vfx` | Block-shaped particles on surface | - |

**Naming Convention**: `{effect}_environment_sdfvfx.vfx`

**WebGPU Demos** (keijiro):
- [SdfVfxTrails](https://www.keijiro.tokyo/WebGPU-Test/SdfVfxTrails/) - Particles constrained to surface
- [SdfVfxStickies](https://www.keijiro.tokyo/WebGPU-Test/SdfVfxStickies/) - Particles stick on approach

### 2.6 SDF Generation

**Unity SDF Bake Tool** (built-in):

**Editor UI**:
1. Window ‚Üí Visual Effects ‚Üí Utilities ‚Üí SDF Bake Tool
2. Assign source mesh
3. Set resolution (16-256, higher = more detail but larger file)
4. Bake ‚Üí Saves .asset file

**Runtime API** (from [Unity Docs - SDF Bake Tool API](https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@13.1/manual/sdf-bake-tool-api.html)):

```csharp
using UnityEngine.VFX.SDF;

// Create baker
var baker = new MeshToSDFBaker(sizeX, sizeY, sizeZ, mesh, meshTransform, signPasses);

// Bake asynchronously
baker.BakeSDF();

// Get result
float[] sdfData = baker.SdfTexture; // Flat array of distance values

// Create Texture3D
Texture3D sdfTexture = new Texture3D(sizeX, sizeY, sizeZ, TextureFormat.RFloat, false);
sdfTexture.SetPixelData(sdfData, 0);
sdfTexture.Apply();

// Bind to VFX
vfx.SetTexture("SDF", sdfTexture);
```

**Best Practices**:
- **Pre-bake in Editor** for static geometry (best performance)
- **Runtime baking** only for dynamic objects (use low res: 32¬≥-64¬≥)
- **Normalized SDFs**: Unity scales mesh so largest side = 1.0 in texture space

### 2.7 AR Foundation Integration

**Use Case**: Environment mesh ‚Üí SDF for particle effects that interact with real-world geometry.

**Example Strategy**:

```csharp
// 1. Get AR mesh
ARMeshManager meshManager = FindFirstObjectByType<ARMeshManager>();
foreach (var meshFilter in meshManager.meshes)
{
    Mesh mesh = meshFilter.sharedMesh;

    // 2. Bake SDF (low-res for real-time)
    var baker = new MeshToSDFBaker(32, 32, 32, mesh, meshFilter.transform.localToWorldMatrix, 1);
    baker.BakeSDF();

    // 3. Create Texture3D
    Texture3D sdf = new Texture3D(32, 32, 32, TextureFormat.RFloat, false);
    sdf.SetPixelData(baker.SdfTexture, 0);
    sdf.Apply();

    // 4. Bind to VFX
    vfx.SetTexture("SDF", sdf);
}
```

**Performance Consideration**: Baking SDF is expensive. For dynamic AR mesh:
- Use low resolution (32¬≥)
- Bake on background thread
- Update every N frames (not every frame)
- Consider pre-baking common room shapes

---

## 3. Comparison: Akvfx vs SdfVfx

| Aspect | Akvfx | SdfVfx |
|--------|-------|--------|
| **Data Type** | 2D textures (PositionMap, ColorMap) | 3D texture (SDF volume) |
| **Input Source** | Depth sensor (Azure Kinect, ARKit, ARCore) | 3D mesh (static or AR mesh) |
| **Particle Behavior** | Point cloud, direct position sampling | Surface constraint, attraction, collision |
| **CPU Cost** | Low (compute shader only) | High (SDF baking), low (runtime use) |
| **GPU Cost** | Moderate (texture sampling) | Moderate (3D texture sampling) |
| **Update Frequency** | Every frame (live sensor) | Infrequent (pre-baked or dynamic mesh) |
| **Use Case** | People tracking, body VFx | Environment effects, architectural VFX |
| **Resolution** | 256√ó192 - 1920√ó1080 (2D) | 16¬≥ - 256¬≥ (3D) |
| **Memory** | ~2-8 MB (2D textures) | ~4-64 MB (3D texture) |
| **Platform** | Azure Kinect: Windows only<br>AR Foundation: iOS/Android | All platforms |

---

## 4. MetavidoVFX Implementation

### 4.1 Akvfx Binding (Production Pattern)

**Setup**: `H3M > VFX Pipeline Master > Setup Complete Pipeline (Recommended)`

**Components**:
1. **ARDepthSource** (singleton) - ONE compute dispatch for ALL VFX
2. **VFXARBinder** (per-VFX) - Lightweight binding (SetTexture only)

**Code Example** (from VFXARBinder.cs):

```csharp
void Update()
{
    if (!Source.IsReady) return;

    // Bind PositionMap (computed by ARDepthSource)
    if (_bindPositionMap && vfx.HasTexture(positionMapProperty))
        vfx.SetTexture(positionMapProperty, Source.PositionMap);

    // Bind ColorMap
    if (_bindColorMap && vfx.HasTexture(colorMapProperty))
        vfx.SetTexture(colorMapProperty, Source.ColorMap);

    // Bind dimensions
    if (Source.PositionMap != null)
    {
        vfx.SetInt("MapWidth", Source.PositionMap.width);
        vfx.SetInt("MapHeight", Source.PositionMap.height);
    }
}
```

### 4.2 SdfVfx Binding (Production Pattern)

**Setup**: Manual (SDF generation required)

**Workflow**:
1. Use Unity SDF Bake Tool to create .asset from mesh
2. Assign SDF asset to VFX property
3. VFX Graph uses SDF nodes (Position On SDF, Attractor SDF, etc.)

**Code Example**:

```csharp
public class SdfVfxBinder : MonoBehaviour
{
    [SerializeField] Texture3D _sdfTexture; // Assigned in Inspector
    VisualEffect _vfx;

    void Start()
    {
        _vfx = GetComponent<VisualEffect>();

        if (_sdfTexture != null && _vfx.HasTexture("SDF"))
            _vfx.SetTexture("SDF", _sdfTexture);
    }
}
```

**No Runtime Compute**: SDF is pre-baked asset, just SetTexture() call.

### 4.3 Property Auto-Detection

VFXARBinder automatically detects which properties a VFX needs:

```csharp
void AutoDetectBindings()
{
    _bindPositionMap = HasAnyProperty(PositionMapAliases);
    _bindColorMap = HasAnyProperty(ColorMapAliases);
    _bindDepthMap = HasAnyProperty(DepthMapAliases);
    _bindStencilMap = HasAnyProperty(StencilMapAliases);
    // ... etc
}

bool HasAnyProperty(string[] aliases)
{
    foreach (var alias in aliases)
        if (_vfx.HasTexture(alias) || _vfx.HasVector4(alias) || _vfx.HasMatrix4x4(alias))
            return true;
    return false;
}
```

**Benefit**: Drop any Akvfx/Rcam/H3M VFX into scene, bindings auto-configure.

---

## 5. Cross-Project Compatibility

### 5.1 Property Name Mapping

VFXARBinder supports multiple naming conventions:

| Standard | Akvfx | Rcam2 | Rcam3 | Rcam4 | H3M |
|----------|-------|-------|-------|-------|-----|
| PositionMap | PositionMap | Position | WorldPosition | WorldPos | PositionMap |
| ColorMap | ColorMap | Color | ColorTexture | CameraColor | MainTex |
| DepthMap | - | Depth | DepthTexture | _Depth | DepthMap |
| StencilMap | - | Stencil | HumanStencil | StencilTexture | StencilMap |

### 5.2 Performance Scaling

**ARDepthSource compute cost**: O(1) regardless of VFX count
**VFXARBinder binding cost**: O(N) but lightweight (~0.3ms per VFX)

**Verified Performance** (2026-01-16):
- 10 active VFX: 353 FPS
- Compute dispatch: ~2ms (single dispatch for all VFX)
- Binding overhead: ~3ms (10 VFX √ó 0.3ms)
- Total GPU time: ~5ms (200 FPS headroom)

---

## 6. Integration Checklist

### 6.1 Akvfx Integration

**‚úÖ Prerequisites**:
- [ ] Unity 6000.2.14f1 or later
- [ ] AR Foundation 6.2.1+
- [ ] VFX Graph 17.2.0+
- [ ] ARKit/ARCore depth support (iPhone 12 Pro+, ARCore depth-enabled Android)

**‚úÖ Setup Steps**:
1. [ ] `H3M > VFX Pipeline Master > Setup Complete Pipeline`
2. [ ] Add Akvfx VFX to scene (Resources/VFX/Akvfx/)
3. [ ] VFXARBinder auto-added and configured
4. [ ] Verify bindings: `H3M > VFX Pipeline Master > Testing > Validate All Bindings`
5. [ ] Test in Editor (AR Foundation Remote) or build to device

**‚úÖ Required Properties** (auto-detected):
- `PositionMap` - RGBAFloat world positions
- `ColorMap` - RGB24 camera texture
- `MapWidth` - int
- `MapHeight` - int

### 6.2 SdfVfx Integration

**‚úÖ Prerequisites**:
- [ ] Unity 6+
- [ ] VFX Graph 17+
- [ ] Source mesh or AR mesh

**‚úÖ Setup Steps**:
1. [ ] Generate SDF: `Window > Visual Effects > Utilities > SDF Bake Tool`
2. [ ] Assign mesh, set resolution (64-128 for static, 32 for dynamic)
3. [ ] Bake ‚Üí Save .asset
4. [ ] Add SdfVfx VFX to scene (Resources/VFX/SdfVfx/)
5. [ ] Assign SDF texture to `SDF` property in Inspector
6. [ ] Test particle behavior (should constrain to SDF surface)

**‚úÖ Required Properties**:
- `SDF` - Texture3D (RFloat format)

**‚úÖ Optional Runtime Baking** (for dynamic AR mesh):
```csharp
var baker = new MeshToSDFBaker(32, 32, 32, mesh, transform, 1);
baker.BakeSDF();
Texture3D sdf = CreateTexture3D(baker.SdfTexture, 32);
vfx.SetTexture("SDF", sdf);
```

---

## 7. Known Issues & Limitations

### 7.1 Akvfx

**Azure Kinect Platform Limitation**:
- ‚ùå Windows only (Azure Kinect SDK limitation)
- ‚úÖ AR Foundation adaptation works iOS/Android

**Depth Quality**:
- ARKit (iPhone): 256√ó192 (720p interpolated)
- ARCore (Android): Variable (device-dependent)
- Quest Pro: 256√ó256 (hand tracking depth)

**Performance**:
- ‚úÖ 353 FPS @ 10 VFX (verified)
- ‚ö†Ô∏è ColorMap allocation is demand-driven (spec-007) - request via `ARDepthSource.RequestColorMap(true)`

### 7.2 SdfVfx

**Baking Performance**:
- ‚ö†Ô∏è Resource-intensive (blocks main thread unless using async API)
- 128¬≥ SDF: ~500ms on M1 MacBook Pro
- 256¬≥ SDF: ~2000ms on M1 MacBook Pro

**Runtime Baking**:
- ‚ö†Ô∏è Only use low resolution (32¬≥-64¬≥) for real-time
- ‚ùå Don't bake every frame unless absolutely necessary
- ‚úÖ Pre-bake common shapes in Editor

**Memory**:
- 32¬≥ √ó 4 bytes = 128 KB
- 64¬≥ √ó 4 bytes = 1 MB
- 128¬≥ √ó 4 bytes = 8 MB
- 256¬≥ √ó 4 bytes = 64 MB

---

## 8. Future Improvements

### 8.1 Akvfx Enhancements

**Potential Additions**:
- [ ] Hand tracking positions (24 joints √ó 2 hands ‚Üí PositionMap)
- [ ] Body tracking skeleton (17 joints ‚Üí PositionMap)
- [ ] Depth confidence map (separate texture for quality filtering)
- [ ] Multi-person support (N √ó body positions)

**Performance**:
- [ ] GPU instancing for identical Akvfx VFX
- [ ] Compute shader optimization (wave intrinsics)

### 8.2 SdfVfx Enhancements

**Dynamic SDF Updates**:
- [ ] Background thread SDF baking (Unity Job System)
- [ ] Incremental SDF updates (only changed regions)
- [ ] SDF streaming (load/unload by distance)

**AR Mesh Integration**:
- [ ] Auto-bake AR mesh to SDF on mesh change
- [ ] SDF pooling (reuse 3D textures)
- [ ] Multi-room SDF management

---

## 9. Code Snippets

### 9.1 Akvfx Complete Example

```csharp
using UnityEngine;
using UnityEngine.VFX;
using UnityEngine.XR.ARFoundation;

/// <summary>
/// Complete Akvfx-style VFX binding for AR Foundation.
/// Drop on any VFX with PositionMap/ColorMap properties.
/// </summary>
[RequireComponent(typeof(VisualEffect))]
public class AkvfxStyleBinder : MonoBehaviour
{
    VisualEffect _vfx;
    ARDepthSource _source;

    void Start()
    {
        _vfx = GetComponent<VisualEffect>();
        _source = ARDepthSource.Instance;

        if (_source == null)
            Debug.LogError("[AkvfxStyleBinder] ARDepthSource.Instance not found!");
    }

    void Update()
    {
        if (_source == null || !_source.IsReady) return;

        // Bind PositionMap (RGBAFloat world positions)
        if (_vfx.HasTexture("PositionMap"))
            _vfx.SetTexture("PositionMap", _source.PositionMap);

        // Bind ColorMap (camera RGB)
        if (_source.ColorMapAllocated && _vfx.HasTexture("ColorMap"))
            _vfx.SetTexture("ColorMap", _source.ColorMap);

        // Bind dimensions
        if (_source.PositionMap != null)
        {
            _vfx.SetInt("MapWidth", _source.PositionMap.width);
            _vfx.SetInt("MapHeight", _source.PositionMap.height);
        }
    }
}
```

### 9.2 SdfVfx Runtime Baking

```csharp
using UnityEngine;
using UnityEngine.VFX;
using UnityEngine.VFX.SDF;
using UnityEngine.XR.ARFoundation;

/// <summary>
/// Bakes AR mesh to SDF and binds to VFX.
/// Use low resolution (32-64) for real-time updates.
/// </summary>
[RequireComponent(typeof(VisualEffect))]
public class ARMeshToSdfBinder : MonoBehaviour
{
    [SerializeField] ARMeshManager _meshManager;
    [SerializeField] int _sdfResolution = 32; // Low-res for real-time
    [SerializeField] int _updateInterval = 30; // Frames between updates

    VisualEffect _vfx;
    Texture3D _sdfTexture;
    int _frameCounter;

    void Start()
    {
        _vfx = GetComponent<VisualEffect>();
        _meshManager ??= FindFirstObjectByType<ARMeshManager>();

        // Pre-allocate Texture3D
        _sdfTexture = new Texture3D(_sdfResolution, _sdfResolution, _sdfResolution,
                                     TextureFormat.RFloat, false);
    }

    void Update()
    {
        if (++_frameCounter < _updateInterval) return;
        _frameCounter = 0;

        // Get first AR mesh (or combine multiple)
        var meshFilters = _meshManager.meshes;
        if (meshFilters.Count == 0) return;

        var meshFilter = meshFilters[0];
        Mesh mesh = meshFilter.sharedMesh;
        if (mesh == null) return;

        // Bake SDF (async recommended for production)
        var baker = new MeshToSDFBaker(_sdfResolution, _sdfResolution, _sdfResolution,
                                        mesh, meshFilter.transform.localToWorldMatrix, 1);
        baker.BakeSDF();

        // Update texture
        _sdfTexture.SetPixelData(baker.SdfTexture, 0);
        _sdfTexture.Apply();

        // Bind to VFX
        if (_vfx.HasTexture("SDF"))
            _vfx.SetTexture("SDF", _sdfTexture);
    }

    void OnDestroy()
    {
        if (_sdfTexture != null)
            Destroy(_sdfTexture);
    }
}
```

### 9.3 VFX Graph HLSL (Akvfx-style)

```hlsl
// In VFX Graph, use Custom HLSL block to sample PositionMap
Texture2D PositionMap;
SamplerState samplerPositionMap;
int MapWidth;
int MapHeight;

// Convert particle ID to UV coordinates
uint particleId = particleId; // From context
float2 uv;
uv.x = (float)(particleId % MapWidth) / (float)MapWidth;
uv.y = (float)(particleId / MapWidth) / (float)MapHeight;

// Sample world position
float4 posData = PositionMap.SampleLevel(samplerPositionMap, uv, 0);
float3 worldPos = posData.xyz;
float confidence = posData.w;

// Use worldPos for particle position
position = worldPos;
```

### 9.4 VFX Graph HLSL (SdfVfx-style)

```hlsl
// In VFX Graph, use built-in SDF nodes or custom HLSL
Texture3D SDF;
SamplerState samplerSDF;

// Sample SDF at world position
float3 worldPos = position; // Particle position
float3 uvw = WorldToSdfUV(worldPos); // Convert to [0,1] texture coords

float distance = SDF.SampleLevel(samplerSDF, uvw, 0).r;

// Particle behavior based on distance
if (distance < 0.0)
{
    // Inside surface - push out
    float3 gradient = ComputeSdfGradient(SDF, uvw);
    position += gradient * abs(distance);
}
else if (distance < 0.1)
{
    // Near surface - stick
    velocity *= 0.95; // Damping
}
```

---

## 10. Resources

### 10.1 Official Documentation

- [Unity VFX Graph - SDF](https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@17.2/manual/sdf-in-vfx-graph.html)
- [SDF Bake Tool API](https://docs.unity3d.com/Packages/com.unity.visualeffectgraph@13.1/manual/sdf-bake-tool-api.html)
- [Dynamic SDF in Unity (GameFromScratch)](https://gamefromscratch.com/dynamic-signed-distance-fields-in-unity/)

### 10.2 GitHub Repositories

- [keijiro/Akvfx](https://github.com/keijiro/Akvfx) - Azure Kinect VFX
- [keijiro/Akvj](https://github.com/keijiro/Akvj) - Akvfx demo project
- [keijiro/SdfVfxSamples](https://github.com/keijiro/SdfVfxSamples) - SDF VFX samples
- [supertask/AkvfxBody](https://github.com/supertask/AkvfxBody) - Body tracking variant

### 10.3 Related Projects

- [keijiro/Smrvfx](https://github.com/keijiro/Smrvfx) - Skinned mesh ‚Üí VFX Graph
- [keijiro/Rsvfx](https://github.com/keijiro/Rsvfx) - RealSense depth ‚Üí VFX Graph
- [keijiro/MetavidoVFX](https://github.com/keijiro/MetavidoVFX) - Volumetric video VFX

### 10.4 MetavidoVFX Reference Files

- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Scripts/Bridges/ARDepthSource.cs`
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Scripts/Bridges/VFXARBinder.cs`
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Resources/VFX/Akvfx/` (7 VFX)
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Resources/VFX/SdfVfx/` (5 VFX)
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Documentation/README.md`

---

## 11. Quick Reference

### 11.1 Akvfx Binding Checklist

```
‚úÖ Add ARDepthSource to scene (singleton)
‚úÖ Add VFXARBinder to VFX GameObject
‚úÖ Enable PositionMap binding
‚úÖ Enable ColorMap binding (optional)
‚úÖ VFX must have PositionMap (Texture2D) property
‚úÖ VFX must have MapWidth/MapHeight (int) properties
‚úÖ Build to device or test with AR Foundation Remote
```

### 11.2 SdfVfx Binding Checklist

```
‚úÖ Bake SDF: Window > Visual Effects > Utilities > SDF Bake Tool
‚úÖ Assign source mesh
‚úÖ Set resolution (64-128 for static, 32 for dynamic)
‚úÖ Save .asset
‚úÖ Add VFX to scene
‚úÖ Assign SDF texture to SDF property
‚úÖ Verify VFX uses SDF nodes (Position On SDF, etc.)
‚úÖ Test particle behavior
```

### 11.3 Performance Targets

| Metric | Target | Verified |
|--------|--------|----------|
| **Akvfx** | | |
| FPS (10 VFX) | 60+ | ‚úÖ 353 FPS |
| Compute Time | <5ms | ‚úÖ ~2ms |
| Binding Time | <0.5ms/VFX | ‚úÖ ~0.3ms |
| **SdfVfx** | | |
| Bake Time (64¬≥) | <200ms | ‚ö†Ô∏è ~150ms |
| Bake Time (128¬≥) | <600ms | ‚ö†Ô∏è ~500ms |
| Runtime Cost | <0.1ms | ‚úÖ negligible |

---

**Document Version**: 1.0
**Last Updated**: 2026-01-20
**Author**: Research compiled by Claude Code (Sonnet 4.5)
**Verified Against**: MetavidoVFX production codebase (Unity 6000.2.14f1)
# LaspVFX Audio-to-VFX Binding Patterns Research

**Research Date**: 2026-01-20
**Repository**: https://github.com/keijiro/LaspVfx (v1.0.3, March 2025)
**Unity Version**: Unity 2022.3+
**Platform Support**: ‚ùå **Desktop ONLY** (Windows, macOS, Linux)

---

## Executive Summary

LaspVFX provides elegant VFX Graph property binders for audio-reactive effects, but relies on **desktop-only LASP plugin** that does NOT support iOS, Android, Quest, or WebGL. Key patterns (ExposedProperty, RFloat textures, NativeArray optimization) are **portable to mobile**, but the audio source must be replaced with `AudioListener.GetSpectrumData()`.

**For MetavidoVFX**: Our existing `AudioBridge.cs` is already mobile-compatible and superior (beat detection, global shader properties, frequency band pre-computation). We can adopt RFloat + NativeArray optimization for performance wins.

---

## 1. Architecture Overview

```
LASP Native Plugin (Desktop Only)
        ‚Üì
AudioLevelTracker / SpectrumToTexture (C# wrappers)
        ‚Üì
VFXBinderBase implementations (4 binders)
        ‚Üì
VFX Graph Properties (Float, Texture2D, UInt32)
```

**Dependency**: `jp.keijiro.lasp` v2.1.7 (Desktop audio input plugin)

---

## 2. VFX Binder Implementations

### A. VFXAudioLevelBinder (Simple Scalar)

**Purpose**: Bind normalized audio level (0-1) to VFX Graph float property.

**Source Code**:
```csharp
using UnityEngine;
using UnityEngine.VFX;
using UnityEngine.VFX.Utility;

namespace Lasp.Vfx
{
    [AddComponentMenu("VFX/Property Binders/LASP/Audio Level Binder")]
    [VFXBinder("LASP/Audio Level")]
    sealed class VFXAudioLevelBinder : VFXBinderBase
    {
        public string Property
          { get => (string)_property; set => _property = value; }

        [VFXPropertyBinding("System.Single"), SerializeField]
        ExposedProperty _property = "AudioLevel";

        public Lasp.AudioLevelTracker Target = null;

        public override bool IsValid(VisualEffect component)
          => Target != null && component.HasFloat(_property);

        public override void UpdateBinding(VisualEffect component)
          => component.SetFloat(_property, Target.normalizedLevel);

        public override string ToString()
          => $"Audio Level : '{_property}' -> {Target?.name ?? "(null)"}";
    }
}
```

**Key Patterns**:
- `[VFXPropertyBinding("System.Single")]` attribute for type safety
- `ExposedProperty` instead of string for property names
- `IsValid()` checks both data source and VFX property existence
- `UpdateBinding()` performs single `SetFloat()` call

**Mobile Adaptation**:
```csharp
// Replace Target.normalizedLevel with:
float level = AudioBridge.Instance.Volume; // Already 0-1 normalized
```

---

### B. VFXAudioGainBinder (Simple Scalar)

**Purpose**: Bind current audio gain (dynamic range compression output) to VFX Graph.

**Source Code**:
```csharp
[VFXBinder("LASP/Audio Gain")]
sealed class VFXAudioGainBinder : VFXBinderBase
{
    [VFXPropertyBinding("System.Single"), SerializeField]
    ExposedProperty _property = "AudioGain";

    public Lasp.AudioLevelTracker Target = null;

    public override bool IsValid(VisualEffect component)
      => Target != null && component.HasFloat(_property);

    public override void UpdateBinding(VisualEffect component)
      => component.SetFloat(_property, Target.currentGain);

    public override string ToString()
      => $"Audio Gain : '{_property}' -> {Target?.name ?? "(null)"}";
}
```

**Mobile Adaptation**:
```csharp
// Replace Target.currentGain with:
float gain = AudioBridge.Instance.Volume * someSensitivityMultiplier;
```

---

### C. VFXSpectrumBinder (Texture + Metadata)

**Purpose**: Bind FFT frequency spectrum as Texture2D + resolution metadata.

**Source Code**:
```csharp
using Unity.Collections;
using UnityEngine;
using UnityEngine.VFX;
using UnityEngine.VFX.Utility;

namespace Lasp.Vfx
{
    [AddComponentMenu("VFX/Property Binders/LASP/Spectrum Binder")]
    [VFXBinder("LASP/Spectrum")]
    sealed class VFXSpectrumBinder : VFXBinderBase
    {
        public string TextureProperty {
            get => (string)_textureProperty;
            set => _textureProperty = value;
        }

        public string ResolutionProperty {
            get => (string)_resolutionProperty;
            set => _resolutionProperty = value;
        }

        [VFXPropertyBinding("UnityEngine.Texture2D"), SerializeField]
        ExposedProperty _textureProperty = "WaveformTexture";

        [VFXPropertyBinding("System.UInt32"), SerializeField]
        ExposedProperty _resolutionProperty = "Resolution";

        public Lasp.SpectrumToTexture Target = null;

        public override bool IsValid(VisualEffect component)
          => Target != null &&
             component.HasTexture(_textureProperty) &&
             component.HasUInt(_resolutionProperty);

        public override void UpdateBinding(VisualEffect component)
        {
            if (Target.texture == null) return;
            component.SetTexture(_textureProperty, Target.texture);
            component.SetUInt(_resolutionProperty, (uint)Target.texture.width);
        }

        public override string ToString()
          => $"Spectrum : '{_textureProperty}' -> {Target?.name ?? "(null)"}";
    }
}
```

**Key Patterns**:
- Multiple property bindings (Texture2D + UInt32)
- Null check before texture access
- Resolution metadata passed separately

**Mobile Adaptation**: Not directly applicable - LASP's SpectrumToTexture is desktop-only. Equivalent would require custom FFT texture generation (like MetavidoVFX's AudioBridge could provide).

---

### D. VFXWaveformBinder (Texture + NativeArray, MOST COMPLEX)

**Purpose**: Bind raw audio waveform samples as Texture2D with performance optimization.

**Source Code**:
```csharp
using Unity.Collections;
using UnityEngine;
using UnityEngine.VFX;
using UnityEngine.VFX.Utility;

namespace Lasp.Vfx
{
    [AddComponentMenu("VFX/Property Binders/LASP/Waveform Binder")]
    [VFXBinder("LASP/Waveform")]
    sealed class VFXWaveformBinder : VFXBinderBase
    {
        #region VFX Binder Implementation

        public string TextureProperty {
            get => (string)_textureProperty;
            set => _textureProperty = value;
        }

        public string TextureWidthProperty {
            get => (string)_textureWidthProperty;
            set => _textureWidthProperty = value;
        }

        public string SampleCountProperty {
            get => (string)_sampleCountProperty;
            set => _sampleCountProperty = value;
        }

        [VFXPropertyBinding("UnityEngine.Texture2D"), SerializeField]
        ExposedProperty _textureProperty = "WaveformTexture";

        [VFXPropertyBinding("System.UInt32"), SerializeField]
        ExposedProperty _textureWidthProperty = "TextureWidth";

        [VFXPropertyBinding("System.UInt32"), SerializeField]
        ExposedProperty _sampleCountProperty = "SampleCount";

        public Lasp.AudioLevelTracker Target = null;

        public override bool IsValid(VisualEffect component)
          => Target != null &&
             component.HasTexture(_textureProperty) &&
             component.HasUInt(_textureWidthProperty) &&
             component.HasUInt(_sampleCountProperty);

        public override void UpdateBinding(VisualEffect component)
        {
            UpdateTexture();
            component.SetTexture(_textureProperty, _texture);
            component.SetUInt(_textureWidthProperty, (uint)MaxSamples);
            component.SetUInt(_sampleCountProperty, (uint)_sampleCount);
        }

        public override string ToString()
          => $"Waveform : '{_textureProperty}' -> {Target?.name ?? "(null)"}";

        #endregion

        #region Waveform texture generation

        const int MaxSamples = 4096;

        Texture2D _texture;
        NativeArray<float> _buffer;
        int _sampleCount;

        void OnDestroy()
        {
            if (_texture != null)
                if (Application.isPlaying)
                    Destroy(_texture);
                else
                    DestroyImmediate(_texture);
        }

        protected override void OnDisable()
        {
            base.OnDisable();
            if (_buffer.IsCreated) _buffer.Dispose();
        }

        void UpdateTexture()
        {
            // Create RFloat texture (single-channel float, 4x smaller than RGBA)
            if (_texture == null)
            {
                _texture =
                  new Texture2D(MaxSamples, 1, TextureFormat.RFloat, false) {
                    filterMode = FilterMode.Bilinear,
                    wrapMode = TextureWrapMode.Clamp
                  };
            }

            // Allocate persistent NativeArray (zero GC allocations)
            if (!_buffer.IsCreated)
                _buffer = new NativeArray<float>
                  (MaxSamples, Allocator.Persistent,
                   NativeArrayOptions.UninitializedMemory);

            // Copy audio samples
            var slice = Target.audioDataSlice;
            _sampleCount = Mathf.Min(_buffer.Length, slice.Length);

            if (_sampleCount > 0)
            {
                slice.CopyTo(_buffer.GetSubArray(0, _sampleCount));
                _texture.LoadRawTextureData(_buffer); // Fast native copy
                _texture.Apply();
            }
        }

        #endregion
    }
}
```

**Key Performance Patterns**:

1. **RFloat Texture Format**:
```csharp
TextureFormat.RFloat // Single-channel float (4 bytes/pixel)
// vs RGBA (16 bytes/pixel) = 4x memory savings
```

2. **NativeArray + Allocator.Persistent**:
```csharp
// Allocated ONCE, reused every frame (zero GC)
_buffer = new NativeArray<float>(MaxSamples, Allocator.Persistent);
```

3. **LoadRawTextureData vs SetPixels**:
```csharp
// Fast: Direct memory copy (no managed array allocation)
_texture.LoadRawTextureData(_buffer);

// Slow: Creates Color[] array, copies, converts
_texture.SetPixels(colorArray);
```

4. **Lazy Initialization**:
```csharp
if (_texture == null) { /* create */ }  // Only once
if (!_buffer.IsCreated) { /* allocate */ }
```

5. **Proper Cleanup**:
```csharp
void OnDestroy() => Destroy(_texture);
protected override void OnDisable() => _buffer.Dispose();
```

**Mobile Adaptation**:
```csharp
// Replace Target.audioDataSlice with:
float[] spectrum = new float[1024];
AudioListener.GetSpectrumData(spectrum, 0, FFTWindow.BlackmanHarris);

// Then copy to NativeArray + texture (same pattern)
NativeArray<float>.Copy(spectrum, _buffer, spectrum.Length);
```

---

## 3. Sample VFX Graphs

| VFX | Size | Purpose |
|-----|------|---------|
| `Lissajous.vfx` | 244KB | Audio-reactive Lissajous curves |
| `Particles.vfx` | 180KB | Audio-driven particle spawning |
| `Spectrogram.vfx` | 120KB | Frequency spectrum visualization |
| `Waveform.vfx` | 85KB | Waveform line renderer |
| `Sample Waveform.vfxoperator` | 28KB | Custom operator for waveform sampling |

**Location**: `keijiro/LaspVfx/Assets/Test/`

---

## 4. Platform Compatibility Matrix

| Platform | LaspVFX Support | AudioListener.GetSpectrumData() | Alternative |
|----------|-----------------|--------------------------------|-------------|
| Windows | ‚úÖ Full | ‚úÖ Available | LASP (native) |
| macOS | ‚úÖ Full | ‚úÖ Available | LASP (native) |
| Linux | ‚úÖ Full | ‚úÖ Available | LASP (native) |
| iOS | ‚ùå **NO** | ‚úÖ Available | Use AudioListener |
| Android | ‚ùå **NO** | ‚úÖ Available | Use AudioListener |
| Quest | ‚ùå **NO** | ‚úÖ Available | Use AudioListener |
| WebGL | ‚ùå **NO** | ‚ùå **NO** | Web Audio API (separate) |

**Critical Notes**:
- LASP requires native desktop audio APIs (WASAPI/CoreAudio/ALSA)
- Mobile platforms MUST use `AudioListener.GetSpectrumData()` instead
- WebGL has NO built-in FFT - requires JavaScript Web Audio API bridge

---

## 5. Comparison: LaspVFX vs MetavidoVFX AudioBridge

| Feature | LaspVFX | MetavidoVFX AudioBridge |
|---------|---------|-------------------------|
| **Platform Support** | Desktop only | ‚úÖ iOS, Android, Quest (NOT WebGL) |
| **Audio Source** | LASP native plugin | `AudioListener.GetSpectrumData()` |
| **Beat Detection** | ‚ùå None | ‚úÖ Adaptive threshold + pulse decay (spec-007) |
| **Frequency Bands** | ‚ùå Manual texture sampling | ‚úÖ 4 pre-computed (SubBass, Bass, Mids, Treble) |
| **Global Shader Access** | ‚ùå Per-VFX bindings only | ‚úÖ `_AudioBands`, `_AudioVolume`, `_BeatPulse` |
| **Texture Fallback** | ‚ùå None | ‚úÖ 2x2 RGBAFloat AudioDataTexture |
| **VFX Graph Binding** | VFXBinderBase (manual setup) | VFXAudioDataBinder + auto-globals |
| **Memory Efficiency** | Excellent (RFloat + NativeArray) | Good (2x2 RGBAFloat texture) |
| **Compute Overhead** | None (texture binding only) | Very low (1024-sample FFT ~0.2ms) |
| **Latency** | <1ms (native callback) | ~16ms (Update() frame delay) |
| **Setup Complexity** | Low (4 simple binders) | Medium (AudioBridge + VFXAudioDataBinder + BeatDetector) |

**Winner for Mobile**: **MetavidoVFX AudioBridge** (only mobile-compatible option)
**Winner for Desktop**: **LaspVFX** (lower latency, simpler code)

---

## 6. Portable Patterns for Mobile

### Pattern 1: ExposedProperty for Type Safety

**LaspVFX**:
```csharp
[VFXPropertyBinding("System.Single")]
ExposedProperty _property = "AudioLevel";

component.SetFloat(_property, value);
```

**MetavidoVFX (Already Uses This)**:
```csharp
[VFXPropertyBinding("System.Single")]
public ExposedProperty volumeProperty = "AudioVolume";

component.SetFloat(volumeProperty, AudioBridge.Instance.Volume);
```

‚úÖ **Portable**: Already standard practice in Unity VFX Graph.

---

### Pattern 2: RFloat Texture Format (4x Memory Savings)

**LaspVFX**:
```csharp
// Single-channel float texture
var texture = new Texture2D(width, 1, TextureFormat.RFloat, false) {
    filterMode = FilterMode.Bilinear,
    wrapMode = TextureWrapMode.Clamp
};
```

**MetavidoVFX Current (Could Optimize)**:
```csharp
// BEFORE: 2x2 RGBAFloat (16 floats = 64 bytes)
_audioDataTexture = new Texture2D(2, 2, TextureFormat.RGBAFloat, false, true);

// AFTER: 4x1 RFloat (4 floats = 16 bytes) - 4x smaller!
_audioDataTexture = new Texture2D(4, 1, TextureFormat.RFloat, false, true) {
    filterMode = FilterMode.Point, // No interpolation needed
    wrapMode = TextureWrapMode.Clamp
};
```

‚úÖ **Portable**: iOS Metal supports RFloat (equivalent to MTLPixelFormatR32Float).

**Data Layout**:
```
BEFORE (2x2 RGBA):
Pixel(0,0): (Volume, Bass, Mids, Treble)
Pixel(1,0): (SubBass, BeatPulse, BeatIntensity, 0)
Pixel(0,1): (0, 0, 0, 0) - wasted
Pixel(1,1): (0, 0, 0, 0) - wasted

AFTER (4x1 R):
Pixel(0,0).r: Volume
Pixel(1,0).r: Bass
Pixel(2,0).r: BeatPulse
Pixel(3,0).r: BeatIntensity
(or pack 8 values in 8x1)
```

---

### Pattern 3: NativeArray + LoadRawTextureData (Zero GC)

**LaspVFX**:
```csharp
// Allocated ONCE in UpdateTexture()
NativeArray<float> _buffer = new NativeArray<float>(4096, Allocator.Persistent);

// Every frame (zero allocations):
slice.CopyTo(_buffer.GetSubArray(0, sampleCount));
texture.LoadRawTextureData(_buffer);
texture.Apply();

// Cleanup in OnDisable():
if (_buffer.IsCreated) _buffer.Dispose();
```

**MetavidoVFX Current (Could Optimize)**:
```csharp
// BEFORE: SetPixels() allocates Color[] array every frame
Color[] _audioDataPixels = new Color[4]; // 4 colors * 16 bytes = 64 bytes GC/frame
_audioDataTexture.SetPixels(_audioDataPixels);
_audioDataTexture.Apply();

// AFTER: NativeArray (zero GC)
NativeArray<float> _audioDataBuffer = new NativeArray<float>(4, Allocator.Persistent);
_audioDataBuffer[0] = Bass;
_audioDataBuffer[1] = Mids;
_audioDataBuffer[2] = BeatPulse;
_audioDataBuffer[3] = BeatIntensity;
_audioDataTexture.LoadRawTextureData(_audioDataBuffer);
_audioDataTexture.Apply();

// Don't forget cleanup:
void OnDestroy() {
    if (_audioDataBuffer.IsCreated) _audioDataBuffer.Dispose();
}
```

‚úÖ **Portable**: NativeArray works on all Unity platforms.

**Performance Impact**:
- Eliminates ~64 bytes GC/frame (at 60fps = 3.8KB/sec)
- Faster texture upload (direct memcpy vs managed array copy)
- Critical for mobile battery life (less GC = less CPU spikes)

---

### Pattern 4: VFXBinder Architecture

**LaspVFX**:
```csharp
[VFXBinder("Category/Name")]
public class CustomBinder : VFXBinderBase
{
    public override bool IsValid(VisualEffect component)
    {
        // Check both data source AND VFX property existence
        return dataSource != null && component.HasFloat(_property);
    }

    public override void UpdateBinding(VisualEffect component)
    {
        // Simple SetFloat/SetTexture calls
        component.SetFloat(_property, dataSource.value);
    }

    public override string ToString()
    {
        // Inspector display string
        return $"Custom : '{_property}' -> {dataSource?.name}";
    }
}
```

‚úÖ **Portable**: Already extensively used in MetavidoVFX (VFXARBinder, VFXAudioDataBinder, etc.).

---

## 7. Performance Characteristics

### LaspVFX (Desktop)
- **CPU**: ~0.1ms/frame (native plugin FFT)
- **GPU**: None (texture binding only)
- **Memory**: ~16KB per waveform texture (4096 floats √ó 4 bytes)
- **Latency**: <1ms (native audio callback thread)
- **GC Pressure**: Zero (NativeArray.Persistent + LoadRawTextureData)

### MetavidoVFX AudioBridge (Mobile)
- **CPU**: ~0.2ms/frame (1024-sample FFT via AudioListener)
- **GPU**: None (CPU-side processing)
- **Memory**: ~64 bytes (2x2 RGBAFloat texture) - could reduce to 16 bytes with RFloat optimization
- **Latency**: ~16ms (Update() frame delay)
- **GC Pressure**: ~64 bytes/frame (Color[] allocation in SetPixels) - eliminates with NativeArray optimization

### Mobile Optimization Recommendations

1. **FFT Size**: Keep ‚â§2048 samples (avoid CPU overhead)
2. **Allocator**: Use `Allocator.Persistent` for NativeArray (zero GC)
3. **Texture Format**: Prefer RFloat over RGBAFloat (4x smaller)
4. **Global Properties**: Prefer global shader properties over per-VFX bindings (fewer SetFloat calls)
5. **Beat Detection**: Enable only when needed (demand-driven, AudioBridge already supports this)

---

## 8. Recommended Optimizations for MetavidoVFX

### Optimization 1: Switch to RFloat Texture (4x Memory Savings)

**File**: `Assets/Scripts/Bridges/AudioBridge.cs`

**Current (line 103)**:
```csharp
_audioDataTexture = new Texture2D(2, 2, TextureFormat.RGBAFloat, false, true)
{
    filterMode = FilterMode.Point,
    wrapMode = TextureWrapMode.Clamp,
    name = "AudioDataTexture"
};
_audioDataPixels = new Color[4]; // 16 floats = 64 bytes
```

**Optimized**:
```csharp
_audioDataTexture = new Texture2D(8, 1, TextureFormat.RFloat, false, true)
{
    filterMode = FilterMode.Point, // No interpolation needed for discrete bands
    wrapMode = TextureWrapMode.Clamp,
    name = "AudioDataTexture"
};
_audioDataBuffer = new NativeArray<float>(8, Allocator.Persistent);
```

**Data Layout** (8x1 RFloat):
```
Pixel 0: Volume
Pixel 1: Bass
Pixel 2: Mids
Pixel 3: Treble
Pixel 4: SubBass
Pixel 5: BeatPulse
Pixel 6: BeatIntensity
Pixel 7: Reserved (future: pitch, spectral centroid, etc.)
```

**Memory**: 64 bytes ‚Üí 32 bytes (2x savings, not 4x because we use 8 values instead of 4)

---

### Optimization 2: Use LoadRawTextureData (Zero GC)

**File**: `Assets/Scripts/Bridges/AudioBridge.cs`

**Current (line 181-195)**:
```csharp
void UpdateAudioDataTexture()
{
    if (!_enableAudioDataTexture || _audioDataTexture == null) return;

    _audioDataPixels[0] = new Color(Volume, Bass, Mids, Treble);
    _audioDataPixels[1] = new Color(SubBass, BeatPulse, BeatIntensity, 0f);
    _audioDataPixels[2] = Color.clear;
    _audioDataPixels[3] = Color.clear;

    _audioDataTexture.SetPixels(_audioDataPixels); // GC allocation
    _audioDataTexture.Apply(false, false);
}
```

**Optimized**:
```csharp
// Add field:
NativeArray<float> _audioDataBuffer;

// In Start(), after texture creation:
_audioDataBuffer = new NativeArray<float>(8, Allocator.Persistent);

// In UpdateAudioDataTexture():
void UpdateAudioDataTexture()
{
    if (!_enableAudioDataTexture || _audioDataTexture == null) return;

    _audioDataBuffer[0] = Volume;
    _audioDataBuffer[1] = Bass;
    _audioDataBuffer[2] = Mids;
    _audioDataBuffer[3] = Treble;
    _audioDataBuffer[4] = SubBass;
    _audioDataBuffer[5] = BeatPulse;
    _audioDataBuffer[6] = BeatIntensity;
    _audioDataBuffer[7] = 0f; // Reserved

    _audioDataTexture.LoadRawTextureData(_audioDataBuffer); // Zero GC
    _audioDataTexture.Apply(false, false);
}

// In OnDestroy(), after texture cleanup:
if (_audioDataBuffer.IsCreated)
    _audioDataBuffer.Dispose();
```

**Benefits**:
- Eliminates ~64 bytes GC/frame (at 60fps = 3.8KB/sec)
- Faster texture upload (native memcpy)
- Better battery life on mobile (less GC pauses)

---

### Optimization 3: VFX Graph Sampling

**VFX Graph Custom HLSL** (sample from RFloat texture):
```hlsl
// Sample audio data from 8x1 RFloat texture
Texture2D<float> AudioDataTexture;

// UV coordinates for each value (center of pixels)
float volume = AudioDataTexture.SampleLevel(samplerAudioDataTexture, float2(0.0625, 0.5), 0); // Pixel 0
float bass = AudioDataTexture.SampleLevel(samplerAudioDataTexture, float2(0.1875, 0.5), 0);   // Pixel 1
float mids = AudioDataTexture.SampleLevel(samplerAudioDataTexture, float2(0.3125, 0.5), 0);   // Pixel 2
float treble = AudioDataTexture.SampleLevel(samplerAudioDataTexture, float2(0.4375, 0.5), 0); // Pixel 3
float beatPulse = AudioDataTexture.SampleLevel(samplerAudioDataTexture, float2(0.6875, 0.5), 0); // Pixel 5

// Or use Load() for exact pixel access (faster):
float volume = AudioDataTexture.Load(int3(0, 0, 0)); // Pixel 0
float bass = AudioDataTexture.Load(int3(1, 0, 0));   // Pixel 1
float beatPulse = AudioDataTexture.Load(int3(5, 0, 0)); // Pixel 5
```

---

## 9. Files Reference

| File | LOC | Purpose | Mobile Compatible |
|------|-----|---------|-------------------|
| `Packages/jp.keijiro.laspvfx/Runtime/VFXAudioLevelBinder.cs` | ~30 | Normalized level (0-1) | ‚úÖ Pattern only |
| `Packages/jp.keijiro.laspvfx/Runtime/VFXAudioGainBinder.cs` | ~30 | Current gain | ‚úÖ Pattern only |
| `Packages/jp.keijiro.laspvfx/Runtime/VFXSpectrumBinder.cs` | ~50 | FFT spectrum texture | ‚úÖ Pattern only |
| `Packages/jp.keijiro.laspvfx/Runtime/VFXWaveformBinder.cs` | ~110 | Raw waveform texture | ‚úÖ Pattern only |
| `Packages/jp.keijiro.laspvfx/Runtime/LaspVfx.Runtime.asmdef` | ~20 | Assembly definition | N/A |

**Total Package Size**: ~240 LOC (excluding LASP dependency)

---

## 10. Next Steps

### For MetavidoVFX Project

1. ‚úÖ **Keep AudioBridge.cs** - Already mobile-compatible, has beat detection
2. ‚úÖ **Keep VFXAudioDataBinder.cs** - Already uses ExposedProperty pattern
3. ‚ö†Ô∏è **Apply RFloat optimization** - Switch AudioDataTexture from RGBAFloat (2x2) to RFloat (8x1)
4. ‚ö†Ô∏è **Apply LoadRawTextureData optimization** - Replace SetPixels() with NativeArray + LoadRawTextureData()
5. ‚ùå **DO NOT port LASP** - Desktop-only, incompatible with iOS/Android/Quest

### Future Research

- Investigate Web Audio API for WebGL audio reactivity (separate from Unity)
- Explore audio-reactive shader patterns that work without FFT (waveform oscillators, noise modulation)
- Consider adding spectral centroid / pitch detection to AudioBridge (EnhancedAudioProcessor already has pitch)

---

## 11. Knowledge Base References

### Internal Documentation
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Scripts/Bridges/AudioBridge.cs` - Current mobile-compatible implementation
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/MetavidoVFX-main/Assets/Scripts/VFX/Binders/VFXAudioDataBinder.cs` - VFX Graph binding
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/KnowledgeBase/_ARFOUNDATION_VFX_KNOWLEDGE_BASE.md` - Audio VFX patterns
- `/Users/jamestunick/Documents/GitHub/Unity-XR-AI/KnowledgeBase/_ML_CV_CROSSPLATFORM_COMPATIBILITY_RESEARCH.md` - WebGL audio limitations

### External References
- https://github.com/keijiro/LaspVfx - LaspVFX source code
- https://github.com/keijiro/Lasp - LASP audio plugin (desktop only)
- https://docs.unity3d.com/ScriptReference/AudioListener.GetSpectrumData.html - Mobile-compatible FFT API
- https://developer.mozilla.org/en-US/Web/API/Web_Audio_API - WebGL alternative

---

## 12. Changelog

**2026-01-20**: Initial research report
- Analyzed LaspVFX v1.0.3 repository structure
- Documented 4 VFX binder implementations
- Identified portable patterns (ExposedProperty, RFloat, NativeArray)
- Compared with MetavidoVFX AudioBridge implementation
- Proposed optimizations (RFloat texture, LoadRawTextureData)
- Confirmed desktop-only platform limitation

---

**License**: Unlicense (LaspVFX), MIT (MetavidoVFX)
**Research By**: Claude Code (Sonnet 4.5)
**Date**: 2026-01-20
# VFX Source Bindings Reference

Authoritative binding specifications for all VFX categories based on original keijiro projects.

## Binding Modes

| Mode | Description | AR Pipeline Required |
|------|-------------|---------------------|
| **AR** | Full AR depth/color pipeline | Yes |
| **Audio** | Audio-reactive (global shader) | No |
| **Keypoint** | ML body keypoints | Partial (ColorMap) |
| **Standalone** | No external data | No |

## Category: Fluo (Audio-Reactive)

**Source**: keijiro/Fluo-GHURT, keijiro/LASP

### Required Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `Throttle` | float | Input | 0-1 intensity |

### Optional Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `AudioLevel` | float | AudioBridge | Sparkles only |
| `Palette` | Gradient | BrushController | Brush.vfx only |

### Global Shader Properties (Auto-bound)
```
_Fluo_AudioLevel (Vector4) = _AudioBands
_Fluo_ThemeColor (Color) = theme color
```

### VFX List
| VFX | Mode | Required | Optional |
|-----|------|----------|----------|
| Bubbles | Audio | Throttle | - |
| Streams | Audio | Throttle | - |
| Confetti | Audio | Throttle | - |
| Sparkles | Audio | Throttle | AudioLevel |
| Brush | Audio | Throttle | Palette |
| Drops | Audio | Throttle | - |
| HUD VFX | Audio | WaveformTexture | AudioLowLevel, AudioMidLevel, AudioHighLevel |

### VFXAudioDataBinder Properties

When `VFXAudioDataBinder` is added to a VFX, it expects these Float properties in the VFX Graph:

| Property | Type | Range | Description |
|----------|------|-------|-------------|
| `AudioVolume` | float | 0-1 | Overall audio level |
| `AudioBass` | float | 0-1 | Low frequency band (20-250Hz) |
| `AudioMid` | float | 0-1 | Mid frequency band (250-4000Hz) |
| `AudioTreble` | float | 0-1 | High frequency band (4000-20000Hz) |
| `AudioSubBass` | float | 0-1 | Sub-bass (20-60Hz) |
| `AudioPitch` | float | Hz | Detected pitch (requires EnhancedAudioProcessor) |
| `BeatPulse` | float | 0-1 | Beat detection pulse (decays after beat) |
| `BeatIntensity` | float | 0-1 | Beat strength |

**Core properties** (recommended minimum): `AudioVolume`, `AudioBass`, `AudioMid`, `AudioTreble`

**Adding properties to VFX Graph**:
1. Open VFX Graph Editor (double-click .vfx asset)
2. Open Blackboard panel (View > Blackboard)
3. Click '+' > Float
4. Name exactly as shown above
5. Check 'Exposed' checkbox

**Menu helper**: `H3M > VFX Pipeline Master > Audio > Show Audio Integration Guide`

### Custom HLSL Audio Access (Advanced)

For VFX without exposed properties, use Custom HLSL Operators to access global audio properties:

**Include File**: `Assets/Shaders/ARGlobals.hlsl`

**Available Functions**:
```hlsl
float GetAudioVolume()      // 0-1 overall volume
float GetAudioBass()        // 0-1 bass band (20-250Hz)
float GetAudioMid()         // 0-1 mid band (250-4000Hz)
float GetAudioTreble()      // 0-1 treble band (4000-20000Hz)
float GetAudioSubBass()     // 0-1 sub-bass band (20-60Hz)
float GetBeatPulse()        // 0-1 decaying beat pulse
float GetBeatIntensity()    // 0-1 beat strength
float4 GetAudioData()       // (volume, bass, mid, treble)
```

**Example Custom HLSL Operator**:
```hlsl
#include "Assets/Shaders/ARGlobals.hlsl"

// Scale particle size by bass
float scale = baseScale * (1.0 + GetAudioBass() * 2.0);

// Pulse color on beat
float3 color = baseColor * (1.0 + GetBeatPulse() * 3.0);
```

**Global Shader Properties** (set by AudioBridge.cs):
| Property | Type | Description |
|----------|------|-------------|
| `_AudioBands` | Vector4 | (bass*100, mids*100, treble*100, subBass*100) |
| `_AudioVolume` | float | 0-1 overall volume |
| `_BeatPulse` | float | 0-1 decaying pulse |
| `_BeatIntensity` | float | 0-1 beat strength |

---

## Category: Rcam2/3/4 (AR Depth)

**Source**: keijiro/Rcam2, keijiro/Rcam3, keijiro/Rcam4

### Required Bindings (People VFX)
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `DepthMap` | Texture2D | ARDepthSource | Required |
| `StencilMap` | Texture2D | ARDepthSource | Human mask |
| `ColorMap` | Texture2D | ARDepthSource | Camera RGB |
| `RayParams` | Vector4 | ARDepthSource | UV‚Üíray |
| `InverseView` | Matrix4x4 | ARDepthSource | Camera pose |

### Required Bindings (Environment VFX)
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `DepthMap` | Texture2D | ARDepthSource | Required |
| `ColorMap` | Texture2D | ARDepthSource | Camera RGB |
| `RayParams` | Vector4 | ARDepthSource | UV‚Üíray |
| `InverseView` | Matrix4x4 | ARDepthSource | Camera pose |

### Optional Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `PositionMap` | Texture2D | ARDepthSource | Pre-computed world pos |
| `VelocityMap` | Texture2D | ARDepthSource | Motion vectors |
| `Throttle` | float | Input | 0-1 intensity |
| `DepthRange` | Vector2 | Config | Near/far clip |

### VFX Naming Convention
- `*_depth_people_*` ‚Üí Requires StencilMap
- `*_environment_*` ‚Üí No StencilMap
- `*_any_*` ‚Üí StencilMap optional

---

## Category: NNCam2 (Keypoint)

**Source**: keijiro/NNCam2

### Required Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `KeypointBuffer` | GraphicsBuffer | BodyPartSegmenter | 17 COCO keypoints |
| `Threshold` | float | Config | Confidence threshold (0.3-0.5) |

### Optional Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `MaskTexture` | Texture2D | BodyPartSegmenter | Body mask |
| `ColorMap` | Texture2D | ARDepthSource | Camera RGB |
| `Throttle` | float | Input | 0-1 intensity |

### VFX List
| VFX | Keypoints Used | Threshold |
|-----|----------------|-----------|
| eyes | 1, 2 | 0.3 |
| joints | All 17 | 0.5 |
| electrify | Limb pairs | 0.4 |
| mosaic | 0-4 (face) | 0.5 |
| tentacles | 9,10,15,16 | 0.4 |
| petals | 0,5,6,11,12 | 0.5 |
| spikes | All joints | 0.4 |
| symbols | All joints | 0.5 |
| particle | All | 0.4 |

---

## Category: Akvfx (Point Cloud)

**Source**: keijiro/Akvfx

### Required Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `PositionMap` | Texture2D | ARDepthSource | World positions (RGBAFloat) |
| `ColorMap` | Texture2D | ARDepthSource | Camera RGB |

### Optional Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `MapWidth` | int | ARDepthSource | Texture width |
| `MapHeight` | int | ARDepthSource | Texture height |
| `Throttle` | float | Input | 0-1 intensity |

### VFX List
- point, web, spikes, voxel, particles, ribbon, trail

---

## Category: SdfVfx (Environment SDF)

**Source**: keijiro/SdfVfxSamples

### Required Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `SDF` | Texture3D | SDF Bake Tool | Pre-baked or runtime |

### Optional Bindings
| Property | Type | Source | Notes |
|----------|------|--------|-------|
| `ColorMap` | Texture2D | ARDepthSource | For coloring |
| `Throttle` | float | Input | 0-1 intensity |

---

## Alias Resolution

VFXARBinder auto-resolves these aliases:

```
DepthMap: Depth, DepthTexture, _Depth
StencilMap: Stencil, HumanStencil, _Stencil
PositionMap: Position, WorldPosition, _Position
ColorMap: Color, ColorTexture, _Color
RayParams: RayParamsMatrix, InverseProjection
InverseView: InverseViewMatrix, CameraToWorld
Throttle: Intensity, Scale
```

---

## Mode Detection Rules

```csharp
// Auto-detect mode from VFX properties
if (HasProperty("KeypointBuffer")) return Mode.Keypoint;
if (HasProperty("DepthMap") || HasProperty("StencilMap")) return Mode.AR;
if (HasProperty("Throttle") && !HasProperty("DepthMap")) return Mode.Audio;
return Mode.Standalone;
```

---

## Specialized Binders (Auto-Added)

VFXPipelineAuditor automatically adds specialized binders when needed:

| Binding | Binder | Added When |
|---------|--------|------------|
| `KeypointBuffer` | NNCamKeypointBinder | VFX has GraphicsBuffer("KeypointBuffer") |
| `Audio` | VFXAudioDataBinder | Mode == Audio or has audio properties |
| `VelocityMap` | VFXPhysicsBinder | VFX uses velocity-based physics |
| Hand tracking | HandVFXController | VFX name contains "hand", "pinch", "brush" |
| Fluo canvas | FluoCanvas | Mode == Audio and name contains "fluo" |

### KeypointBuffer (Specialized Binding)

`KeypointBuffer` is NOT a VFXARBinder binding - it requires `NNCamKeypointBinder`:

```csharp
// KeypointBuffer structure (17 COCO keypoints)
struct Keypoint {
    float3 position;  // UV or world position
    float score;      // Confidence 0-1
};

// Keypoint indices
0: nose, 1-2: eyes, 3-4: ears, 5-6: shoulders,
7-8: elbows, 9-10: wrists, 11-12: hips,
13-14: knees, 15-16: ankles
```

---

## Auto-Fix Behavior

`H3M > VFX Pipeline Master > Audit & Fix` automatically:

1. **Detects binding mode** from VFX properties
2. **Adds VFXARBinder** with required AR bindings (AR/Keypoint modes)
3. **Adds specialized binders** (NNCamKeypointBinder, VFXAudioDataBinder, etc.)
4. **Adds VFXNoCull** for screen-space VFX (NNCam, screen-space effects)
5. **Adds VFXCategory** for mode-based management
6. **Does NOT edit VFX Graph files** - all binding via runtime components

### Override with custom-bindings.md

User can override auto-detection in `Assets/Documentation/custom-bindings.md`:

```yaml
eyes_any_nncam2:
  mode: Keypoint
  bindings:
    ColorMap: true
    Throttle: false
```

---

---

## UV-to-World Algorithm (Keijiro Pattern)

**Used in**: VFX Operators, Custom HLSL Blocks

```hlsl
float3 ARInverseProjection(float2 UV, float Depth, float4 RayParams, float4x4 InverseView)
{
    // 1. UV [0,1] to NDC [-1,1]
    float3 ray = float3((UV - 0.5) * 2, 1);

    // 2. Apply camera intrinsics (principal point + FOV)
    ray.xy = (ray.xy + RayParams.xy) * RayParams.zw;
    //        ^^^^^^^^^^^^^^^^^^^^^^   ^^^^^^^^^^^^^^
    //        Principal point offset   tan(FOV/2) scale

    // 3. Scale by depth distance
    ray *= Depth;

    // 4. Transform camera space to world space
    return mul(InverseView, float4(ray, 1)).xyz;
}
```

**RayParams Computation** (C#):
```csharp
public static Vector4 ComputeRayParams(Camera arCamera)
{
    var proj = arCamera.projectionMatrix;
    float centerShiftX = proj.m02;  // Principal point X
    float centerShiftY = proj.m12;  // Principal point Y
    float fov = arCamera.fieldOfView * Mathf.Deg2Rad;
    float tanV = Mathf.Tan(fov * 0.5f);
    float tanH = tanV * arCamera.aspect;

    return new Vector4(centerShiftX, centerShiftY, tanH, tanV);
}
```

**iOS Portrait Fix**: ARKit depth is always landscape. Apply 90¬∞ rotation:
```csharp
float2 uv = i.uv;
uv = float2(1.0 - uv.y, uv.x);  // 90¬∞ clockwise
```

---

## References

- **Full VFX Spec**: `portals_main/specs/VFX_ARCHITECTURE.md`
- **O(1) Compute Pattern**: `portals_main/specs/VFX_ARCHITECTURE.md` ¬ßArchitecture
- **MetavidoVFX Source**: `Unity-XR-AI/References/MetavidoVFX-main/`

---

*Generated from keijiro source projects research 2026-01-20*
*Updated with UV-to-world algorithm and references 2026-02-05*
# VFX Sources Registry

**Total VFX**: 235 assets in Resources/VFX
**Categories**: 29 folders
**Last Updated**: 2026-02-05

---

## Quick Reference (Mobile AR)

| Constraint | Value | Source |
|------------|-------|--------|
| Max particles (iPhone 12+) | 50,000 | Profiled |
| VFX per scene budget | 5-7 | ~0.2ms each binding |
| Compute thread groups | 32√ó32 | Mobile Metal optimal |
| Depth texture format | RHalf (R16F) | Sufficient precision |

**O(1) Compute Pattern** (from MetavidoVFX):
```
ARDepthSource.cs (SINGLETON) ‚Üí One compute dispatch/frame
    ‚Üì Outputs: PositionMap, StencilMap, VelocityMap
VFXARBinder.cs (per VFX, LIGHTWEIGHT ~0.2ms)
    ‚Üì Just SetTexture() calls, no compute
VFX Graph (renders particles)
```

**Naming Convention**: `{effect}_{datasource}_{target}_{origin}.vfx`
- effect: particles, sparkles, grid, trails, voxels
- datasource: depth, stencil, mesh, audio, environment
- target: people, hands, face, environment, any
- origin: rcam4, metavido, h3m, portals, keijiro

---

## VFX Pipeline Types

| Pipeline | Input | Processing | VFX Count |
|----------|-------|------------|-----------|
| **Metavido (Raw Depth)** | DepthMap + RayParams + InverseView | VFX-internal reconstruction | ~44 |
| **H3M Stencil** | PositionMap + StencilMap | DepthToWorld.compute | ~9 |
| **NNCam2 Keypoints** | KeypointBuffer (17 landmarks) | BodyPartSegmenter | 9 |
| **Environment** | Spawn control only | None | ~23 |
| **Audio Reactive** | AudioVolume + AudioBands | AudioBridge FFT | ~12 |
| **SDF-based** | SDF textures | Particle shaping | ~10 |

## VFX Sources by Origin

### Core MetavidoVFX (Original)
- **Location**: `Resources/VFX/People`, `Environment`
- **Count**: ~14 VFX
- **Pipeline**: Metavido Raw Depth

### Keijiro Projects
| Source | Repo | VFX Count | Category |
|--------|------|-----------|----------|
| **Rcam2** | keijiro/Rcam2 | 20 | HDRP‚ÜíURP converted |
| **Rcam3** | keijiro/Rcam3 | 8 | Depth people/env |
| **Rcam4** | keijiro/Rcam4 | 14 | NDI-style body |
| **Akvfx** | keijiro/Akvfx | 7 | Azure Kinect |
| **Khoreo** | keijiro/Khoreo | 7 | Stage performance |
| **Fluo** | keijiro/Fluo | 8 | Brush/painting |
| **Smrvfx** | keijiro/Smrvfx | 2 | Skinned mesh |
| **SdfVfx** | keijiro/SdfVfx | 5 | SDF generation |
| **VfxGraphTestbed** | keijiro/VfxGraphTestbed | 16 | Experimental |
| **SplatVFX** | keijiro/SplatVFX | 3 | Gaussian splatting |
| **LaspVfx** | keijiro/LaspVfx | 4 | Audio reactive (LASP) |
| **Anomask** | keijiro/Anomask | 1 | Face anonymizer (URP) |
| **FloatingHUD** | keijiro/FloatingHUD | 1 | HUD projector (URP) |
| **GeoVfx** | keijiro/GeoVfx | 2 | Data visualization |
| **DrumPadVFX** | keijiro/DrumPadVFX | 1 | Audio reactive drums |
| **Testbed4** | keijiro/VfxGraphTestbed4 | 3 | Environment effects |

### HoloKit/Holoi Projects
| Source | Repo | VFX Count | Category |
|--------|------|-----------|----------|
| **Buddha** | holoi/touching-hologram | 21 | Hand-tracked mesh |
| **NNCam2** | jp.keijiro.nncam2 | 9 | Keypoint-driven |

### Unity Official
| Source | Origin | VFX Count | Category |
|--------|--------|-----------|----------|
| **UnitySamples** | Procedural VFX Library | 20 | Learning templates |
| **Portals6** | Unity Portals Demo | 22 | Portal effects |

### Third-Party Projects
| Source | Repo | VFX Count | Category |
|--------|------|-----------|----------|
| **FaceTracking** | mao-test-h/FaceTrackingVFX | 2 | ARKit face mesh |
| **MinimalCompute** | cinight/MinimalCompute | 2 | Compute examples |
| **MyakuMyakuAR** | plantblobs | 1 | AR character |
| **TamagotchU** | EyezLee/TamagotchU | 4 | Virtual pet |
| **WebRTC** | URP-WebRTC-Convai | 7 | Trails + SDF |
| **Essentials** | VFX-Essentials-main | 22 | Boids, noise, waveform, etc. |
| **Dcam2** | keijiro/Dcam2 | 13 | Depth camera visualizer |

## Key VFX Property Bindings

### AR Pipeline (ARDepthSource)
```
DepthMap      Texture2D  Raw AR depth (RFloat)
StencilMap    Texture2D  Human segmentation mask
PositionMap   Texture2D  GPU-computed world XYZ
ColorMap      Texture2D  Camera RGB
VelocityMap   Texture2D  Motion vectors
RayParams     Vector4    (0, 0, tan(fov/2)*aspect, tan(fov/2))
InverseView   Matrix4x4  Camera inverse view
DepthRange    Vector2    Near/far clip (0.1-10m)
```

### Audio Pipeline (AudioBridge)
```
AudioVolume   float      0-1 overall volume
AudioBands    Vector4    (bass, mid, treble, sub)
```

### Keypoint Pipeline (NNCamKeypointBinder)
```
KeypointBuffer  GraphicsBuffer  17 pose landmarks
```

## Folder Structure

```
Resources/VFX/
‚îú‚îÄ‚îÄ Portals6/       (22)   Portal effects
‚îú‚îÄ‚îÄ Essentials/     (22)   Boids, noise, waveform
‚îú‚îÄ‚îÄ Buddha/         (21)   Hand-tracked mesh
‚îú‚îÄ‚îÄ UnitySamples/   (20)   Learning templates
‚îú‚îÄ‚îÄ Rcam2/          (20)   HDRP‚ÜíURP body
‚îú‚îÄ‚îÄ Keijiro/        (16)   Experimental
‚îú‚îÄ‚îÄ Rcam4/          (14)   NDI-style body
‚îú‚îÄ‚îÄ Dcam/           (13)   Depth camera vis
‚îú‚îÄ‚îÄ NNCam2/          (9)   Keypoint-driven
‚îú‚îÄ‚îÄ Rcam3/           (8)   Depth people/env
‚îú‚îÄ‚îÄ Fluo/            (8)   Brush/painting
‚îú‚îÄ‚îÄ WebRTC/          (7)   Trails + SDF
‚îú‚îÄ‚îÄ Khoreo/          (7)   Stage performance
‚îú‚îÄ‚îÄ Akvfx/           (7)   Azure Kinect style
‚îú‚îÄ‚îÄ People/          (5)   Core body effects
‚îú‚îÄ‚îÄ Environment/     (5)   World-space effects
‚îú‚îÄ‚îÄ SdfVfx/          (5)   SDF generation
‚îú‚îÄ‚îÄ LaspVfx/         (4)   Audio reactive (LASP)
‚îú‚îÄ‚îÄ Tamagotchu/      (4)   Virtual pet
‚îú‚îÄ‚îÄ Testbed4/        (3)   Age, Flame, Random
‚îú‚îÄ‚îÄ Splat/           (3)   Gaussian splatting
‚îú‚îÄ‚îÄ GeoVfx/          (2)   Population, Temperature
‚îú‚îÄ‚îÄ Smrvfx/          (2)   Skinned mesh
‚îú‚îÄ‚îÄ FaceTracking/    (2)   Face mesh
‚îú‚îÄ‚îÄ Compute/         (2)   Compute examples
‚îú‚îÄ‚îÄ Anomask/         (1)   Face anonymizer
‚îú‚îÄ‚îÄ FloatingHUD/     (1)   HUD projector
‚îú‚îÄ‚îÄ DrumPad/         (1)   Audio drums
‚îî‚îÄ‚îÄ Myaku/           (1)   AR character
```

## GitHub Repos Referenced

- keijiro/Rcam2, Rcam3, Rcam4
- keijiro/Akvfx, Smrvfx, SdfVfx
- keijiro/Khoreo, Fluo
- keijiro/VfxGraphTestbed, VfxGraphTestbed4
- keijiro/SplatVFX
- keijiro/LaspVfx, Anomask, FloatingHUD
- keijiro/GeoVfx, DrumPadVFX
- holoi/touching-hologram
- mao-test-h/FaceTrackingVFX
- cinight/MinimalCompute
- EyezLee/TamagotchU
- Unity VFX Graph samples

## Migration History

| Date | Source | VFX Count | Commit |
|------|--------|-----------|--------|
| 2026-01-14 | Rcam2-4, Akvfx, SdfVfx | 54 | Initial setup |
| 2026-01-16 | NNCam2 | 9 | Keypoint VFX |
| 2026-01-20 | Portals6 | 22 | Portal effects |
| 2026-01-20 | Buddha, Fluo, Khoreo, etc | 76 | Reference migration |
| 2026-01-20 | _ref projects | 17 | Final migration |
| 2026-01-20 | VFX-Essentials, Dcam2 | 35 | Final batch |
| 2026-01-20 | LaspVfx, Anomask, FloatingHUD | 6 | Audio + HUD VFX |
| 2026-01-20 | GeoVfx, DrumPadVFX, Testbed4 | 6 | Data viz + Env |

## Original Names Registry

All VFX retain their original names from source repos. No renames have been performed.

**Naming Convention**: `name_type_source.vfx` (planned, not yet applied)
- `name`: Descriptive effect name
- `type`: people, env, audio, hand, face, hybrid
- `source`: Origin project abbreviation

**Documentation Generated**:
- `Assets/Documentation/VFX_Bindings/` - Per-VFX binding docs
- `_MASTER_VFX_BINDINGS.md` - Aggregated bindings reference
- `_VFX_ORIGINAL_NAMES_REGISTRY.md` - Pre-rename tracking

**Editor Tool**: `H3M > VFX Pipeline Master > Binding Docs > Generate All Binding Docs`

## Auto-Binding Integration

VFXLibraryManager integrates with VFXBindingDocGenerator:
1. **Audit**: VFXCompatibilityAuditor scans exposed properties
2. **Bind**: VFXARBinder auto-detects and binds AR properties
3. **Document**: VFXBindingDocGenerator creates per-VFX docs
4. **Track**: Original names preserved in registry
