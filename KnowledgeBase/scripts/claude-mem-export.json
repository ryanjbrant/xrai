{"ids": ["unity-xr-ai-session-2026-01-16-init", "metavidovfx-hybrid-bridge-2026-01-16", "metavidovfx-testing-checklist-2026-01-16", "metavidovfx-platform-compat-2026-01-16", "vfx-graph-global-texture-limitation-2026-01", "csharp-ref-property-limitation-cs0206", "hybrid-bridge-pattern-metavidovfx-2026-01", "vfx-graph-webgl-incompatibility-2026-01", "vfxpipelinedashboard-pattern-2026-01", "vfxtestharness-pattern-2026-01", "global_rules_session_start_2026-01-16", "never_delete_rule_james_2026-01-16", "pref-mcp-cleanup-2026-01-19", "pref-token-optimization-2026-01-19", "metavidovfx-ar-texture-fix-2026-01-20", "metavidovfx-spec007-phases1-3-2026-01-20", "startup-mcp-cleanup-2026-01-20", "nncam-eyes-fix-2026-01-20", "unity-xrai-architecture-2026-01-20", "metavido-key-scripts-2026-01-20", "unity-mcp-usage-2026-01-20", "metavidovfx-hifi-hologram-session-2026-01-21", "metavidovfx-hologram-scene-structure-2026-01-21", "unity-xr-ai-session-2026-01-22-bugfix", "warpjobs-session-2026-02-05-scoring-calendar", "metavidovfx-session-2026-02-06-audit-memory", "session-persistence-rule-20260206", "xrai-spec-kb-search-results-2026-02-12"], "documents": ["Unity-XR-AI Project Session - 2026-01-16\n\nProject: Unity-XR-AI knowledgebase and MetavidoVFX Unity project\nLocation: /Users/jamestunick/Documents/GitHub/Unity-XR-AI\n\nKey Components:\n- KnowledgeBase: 75+ MD files, 520+ GitHub repo references\n- MetavidoVFX-main: Unity 6000.2.14f1 AR Foundation VFX project\n- AgentBench: Unity source code research workbench\n- Vis: 10 visualization frontends (xrai-kg, HOLOVIS, etc.)\n\nCore Architecture:\n- VFXBinderManager: Central hub for AR data \u2192 VFX binding\n- H3M Hologram system: HologramSource, HologramRenderer, HologramAnchor\n- 73 custom C# scripts, 65+ VFX Graph effects\n\nSession Activity:\n- Initialized claude-mem collection for persistent memory\n- Running in 'learning' output style mode\n\nTags: unity-xr-ai, metavidovfx, ar-foundation, vfx-graph, knowledgebase", "MetavidoVFX VFX Pipeline - Hybrid Bridge Pattern (2026-01-16)\n\nRECOMMENDED ARCHITECTURE:\n- ARDepthSource (singleton, ~80 LOC) - ONE compute dispatch\n- VFXARBinder (per-VFX, ~40 LOC) - lightweight SetTexture() binding\n\nKEY INSIGHT: VFX Graph cannot read Shader.SetGlobalTexture() - must use explicit vfx.SetTexture()\n\nQUICK SETUP: H3M > VFX Pipeline > Setup Hybrid Bridge (Recommended)\n\nPERFORMANCE:\n- 1 VFX: 1.15ms (vs 1.1ms old)\n- 10 VFX: 1.6ms (vs 11ms old)\n- 20 VFX: 2.1ms (vs 22ms old)\n\nLEGACY (DISABLED):\n- VFXBinderManager.cs \u2192 replaced by ARDepthSource\n- VFXARDataBinder.cs \u2192 replaced by VFXARBinder\n\nFEATURES:\n- VelocityMap: +0.4ms (CalculateVelocity kernel)\n- BodyPixSentis: +4.8ms (24-part segmentation, optional)\n\nVFX NAMING: {effect}_{datasource}_{target}_{origin}.vfx\nExample: particles_depth_people_metavido.vfx\n\nDOCUMENTATION: Assets/Documentation/VFX_PIPELINE_FINAL_RECOMMENDATION.md", "MetavidoVFX Testing & Debugging Checklist (2026-01-16)\n\nTRIPLE-VERIFIED WORKFLOW:\n1. Unity Console Check: mcp__UnityMCP__read_console after every edit\n2. Play Mode Test: Enter Play mode, check VFX renders correctly\n3. Device Test: Build to iOS, verify on-device\n\nVERBOSE LOGGING PATTERN:\n```csharp\n[Header(\"Debug\")]\npublic bool verboseLogging = false;\nvoid Update() {\n    if (verboseLogging) Debug.Log($\"[{name}] Status: {status}\");\n}\n```\n\nCOMMON DEBUG POINTS:\n- ARDepthSource: Check DepthMap != null, PositionMap dimensions\n- VFXARBinder: Verify source.DepthMap available, vfx.HasTexture() returns true\n- RayParams: Log values to verify aspect ratio correct\n\nMCP TOOLS FOR TESTING:\n- read_console: Check compilation errors\n- manage_editor(action=\"play\"): Start Play mode\n- find_gameobjects: Locate VFX in scene\n- manage_components: Inspect component properties\n\nPERFORMANCE TARGETS:\n- 60 FPS on iPhone 15 Pro\n- <2ms compute per frame\n- <0.1ms binding per VFX", "MetavidoVFX Platform Compatibility (2026-01-16): VFX Graph requires compute shaders - WebGL 2.0 NOT SUPPORTED. react-unity-webgl inherits WebGL limitations. iOS/Android/Quest = full support. WebGPU experimental in Unity 6.1+. Web alternatives: 1) WebGPU future, 2) Legacy ParticleSystem fallback, 3) WebRTC video streaming from device. Key sources: Unity docs, keijiro/VfxGraphGraphicsBufferTest (86 stars). Triple-verified against official Unity documentation and GitHub sources.", "VFX Graph Global Property Limitation (Unity 6 VFX Graph 17.2): VFX Graph CANNOT read textures from Shader.SetGlobalTexture() - it only works for regular shaders. VFX must use explicit vfx.SetTexture() per-VFX instance. HOWEVER, GraphicsBuffers work globally via Shader.SetGlobalBuffer() because VFX can access them through HLSL includes. Vector4/Matrix4x4 globals also work. This is why Hybrid Bridge Pattern uses ARDepthSource singleton + VFXARBinder per-VFX binding. Verified via Unity Discussions Jan 2026.", "C# Properties Cannot Be Passed as ref/out Parameters: In C#, auto-properties like 'public RenderTexture PositionMap { get; private set; }' cannot be used with ref/out. Must use backing fields: 'RenderTexture _positionMap; public RenderTexture PositionMap => _positionMap;' then 'EnsureRenderTexture(ref _positionMap, ...)'. This is a language limitation, not Unity-specific. Error CS0206.", "Hybrid Bridge Pattern for VFX (MetavidoVFX 2026-01-16): O(1) compute dispatch + O(N) lightweight binding. ARDepthSource singleton does ONE GPU compute dispatch per frame for ALL VFX, computes PositionMap/VelocityMap. VFXARBinder per-VFX does just SetTexture() calls - no compute. Scales linearly: 1 VFX = ~2ms, 10 VFX = ~5ms, 20 VFX = ~8ms. Reference: YoHana19/HumanParticleEffect pattern (~200 lines vs VFXBinderManager 1357 lines).", "VFX Graph WebGL 2.0 Incompatibility: VFX Graph requires compute shader support which WebGL 2.0 lacks. VFX effects will NOT work with react-unity-webgl portals or any WebGL deployment. Must use Particle Systems for WebGL or target native platforms only. Verified Jan 2026.", "VFXPipelineDashboard Pattern (MetavidoVFX): IMGUI-based real-time debug overlay showing: FPS graph (60-frame history), pipeline flow visualization (ARDepthSource\u2192VFXARBinder\u2192VFX), binding status with color indicators, memory usage (RenderTexture allocations), active VFX list with particle counts. Toggle with Tab key. Uses OnGUI() for cross-platform compatibility.", "VFXTestHarness Pattern (MetavidoVFX): Keyboard shortcuts for rapid VFX testing: 1-9=favorites, Space=cycle next, C=cycle categories, A=toggle all, P=auto-cycle profiling mode, R=refresh list. Auto-categorizes VFX by naming convention (people/human/body\u2192People, hand/joint\u2192Hands, audio/sound\u2192Audio, rcam/metavido/nncam\u2192by source). Uses InferCategory() method for smart categorization.", "CRITICAL SESSION START RULE: Always load and follow ~/GLOBAL_RULES.md at the start of every session. This file contains: (1) File Safety - NEVER delete files without explicit permission, (2) Debugging protocols, (3) MCP-first verification, (4) Process awareness - never kill without verification, (5) Unity/WebGL/3DVis intelligence patterns, (6) Spec-driven development, (7) Persistent learning requirements. User James requires strict adherence to these rules. Read GLOBAL_RULES.md BEFORE taking any actions.", "USER RULE - NEVER DELETE FILES: James requires that files are NEVER deleted without his explicit permission saying 'delete' or 'remove'. Moving, renaming, marking as deprecated = OK. Deleting = ONLY with explicit instruction. This rule applies to ALL projects, ALL files, ALL sessions. Violation of this rule is unacceptable. When in doubt, ASK before any destructive action.", "STARTUP TASK: At the beginning of every Claude Code session, automatically check for and kill unused/duplicate MCP server instances. Run 'ps aux | grep mcp' to identify duplicates from old sessions (different terminal sessions like s011, s015) and terminate them. Keep only the instances needed for the current session. This keeps the system clean and prevents resource waste.", "CRITICAL PREFERENCE: Always minimize token usage. Keep responses concise, use agents for independent token budgets, avoid redundant tool calls, batch operations, reference existing docs instead of duplicating. See ~/.claude/docs/TOKEN_OPTIMIZATION.md for full strategies.", "MetavidoVFX Session 2026-01-20: Fixed AR Foundation Texture Access Crash (BUG 6)\n\n## Summary\nFixed critical startup crash caused by AR Foundation texture property getters throwing NullReferenceException when AR subsystem isn't ready. The `?.` null-coalescing operator does NOT protect because exception happens inside the getter.\n\n## TryGetTexture Pattern (KEY FIX)\n```csharp\nTexture TryGetTexture(System.Func<Texture> getter)\n{\n    try { return getter?.Invoke(); }\n    catch { return null; }\n}\nvar depth = TryGetTexture(() => occlusionManager.humanDepthTexture);\n```\n\n## Files Fixed (6 total)\n- ARDepthSource.cs\n- SimpleHumanHologram.cs  \n- DiagnosticOverlay.cs\n- DirectDepthBinder.cs\n- HumanParticleVFX.cs\n- DepthImageProcessor.cs\n\n## Commits\n- ed280f8d2: fix(AR): Add TryGetTexture pattern for safe AR texture access\n- 945cfb8fa: docs: Document BUG 6 - AR texture access NullReferenceException fix\n\n## Deploy Notes\n- WiFi deploy kept failing at ~10-17% (device disconnect)\n- Solution: Use `ios-deploy --no-wifi` for USB-only deploy\n- Device: IMClab 15 (iOS 26.2)\n\n## Documentation Updated\n- CODEBASE_AUDIT_2026-01-15.md: Added BUG 6 section\n- QUICK_REFERENCE.md: Added TryGetTexture to Common Fixes\n\n#MetavidoVFX #ARFoundation #BugFix #TryGetTexture #iOS #Unity", "MetavidoVFX Spec 007: Phases 1-3 complete. Created VFXModeController for runtime mode switching between different VFX categories. Implemented BeatDetector with spectral flux analysis for audio-reactive VFX. Added demand-driven VFX loading patterns for efficient memory usage. Project: Unity-XR-AI/MetavidoVFX. Date: 2026-01-20.", "CRITICAL STARTUP TASK: Always run `mcp-kill-dupes` immediately when starting a new Claude Code session. Multiple Claude sessions spawn duplicate MCP server processes (mcp-for-unity, chroma-mcp, github) which cause significant CPU overhead and slow down both Claude Code and Rider IDE. Stale Claude sessions that weren't properly closed with /exit leave orphan MCP processes running. Check with: ps aux | grep mcp-for-unity | grep -v grep | wc -l - should be 1 per active session. Kill extras manually if mcp-kill-dupes misses them.", "NNCam Eyes VFX Fix (2026-01-20): eyes_any_nncam2.vfx needs world-space positioning. Solution: Wire existing 'Get Keypoint World' subgraph (Assets/VFX/NNCam2/Get Keypoint World.vfxoperator) which takes KeypointBuffer + PositionMap and outputs world Position. The subgraph already exists - just needs to be connected inside the eyes VFX. PositionMap is in the Blackboard but not wired. Key insight: Always check for existing solutions before creating new code. The compute shader approach was unnecessary since VFX subgraphs already handle UV\u2192world position conversion.", "Unity-XR-AI project architecture: MetavidoVFX is the main Unity project using AR Foundation 6.2.1, VFX Graph 17.2.0, Unity 6000.2.14f1. Core systems: ARDepthSource (single compute dispatch), VFXARBinder (per-VFX texture mapping), VFXLibraryManager (73 VFX organized by category). Performance verified at 353 FPS with 10 active VFX. Key patterns: Hybrid Bridge Pattern for O(1) compute scaling, ExposedProperty for VFX Graph bindings.", "MetavidoVFX key scripts and locations: ARDepthSource.cs (Assets/Scripts/Bridges) - primary AR data source; VFXARBinder.cs (Assets/Scripts/Bridges) - lightweight per-VFX binder; VFXLibraryManager.cs (Assets/Scripts/VFX) - 920 LOC manager for all VFX; NNCamKeypointBinder.cs (Assets/NNCam/Scripts) - body tracking to VFX; HandVFXController.cs - velocity-driven hand tracking with pinch detection.", "Unity MCP integration: Use mcp__UnityMCP tools for editor control. Key tools: manage_scene (hierarchy, screenshot), manage_gameobject (CRUD), find_gameobjects (search), manage_components (add/remove), read_console (errors). Always check read_console after script changes for compilation errors. Use batch_execute for multiple operations.", "MetavidoVFX HiFi Hologram Session 2026-01-21\n\n## Key Scene Objects (HOLOGRAM.unity)\n- Hologram (parent) - ID: 128402 - Contains HologramPlacer, HologramController, VideoPlayer, MetadataDecoder, TextureDemuxer\n- Hologram/HologramVFX (child) - ID: 129162 - Contains VisualEffect, VFXARBinder, VFXCategory\n\n## Key Scripts Created\n1. Assets/Shaders/HiFiHologramVFX.hlsl - HLSL sampling functions for PositionMap + ColorMap\n2. Assets/Scripts/Editor/HiFiHologramVFXCreator.cs - Menu: H3M > HiFi Hologram\n3. Assets/Scripts/Editor/RealisticHologramSetup.cs - Menu: H3M > Hologram > Setup Realistic RGB Hologram\n\n## Key Architecture Insight\n- Metavido VFX computes depth\u2192position per-particle in HLSL (MetavidoInverseProjection)\n- ARDepthSource computes PositionMap via GPU compute shader (one dispatch)\n- Using both = redundant computation (depth\u2192position computed twice)\n- HiFi approach: Read PositionMap directly + ColorMap for RGB (no redundant computation)\n\n## VFXARBinder Property Bindings\n- DepthMap, StencilMap, PositionMap, VelocityMap, ColorMap\n- RayParams (Vector4), InverseView (Matrix4x4)\n- MapWidth, MapHeight (float), Dimensions (Vector2 for Rcam4)\n- PosAliases: PositionMap, Position, WorldPosition, Positions\n\n## Menu Commands\n- H3M > HiFi Hologram > Create Optimized HiFi Hologram VFX\n- H3M > HiFi Hologram > Add to Hologram Prefab\n- H3M > Hologram > Setup Realistic RGB Hologram\n- H3M > VFX Pipeline Master > Setup Complete Pipeline", "MetavidoVFX HOLOGRAM.unity Scene Structure (2026-01-21)\n\n## Critical Scene Objects\n\n### AR Pipeline\n- ARDepthSource (ID: 129478) - Singleton compute source, ONE dispatch for all VFX\n  Path: /ARDepthSource\n  Components: Transform, ARDepthSource\n  Provides: DepthMap, StencilMap, PositionMap, VelocityMap, ColorMap, RayParams\n\n### AR Camera\n- AR Camera (ID: 129600) - Main camera with AR components\n  Path: HoloKit Camera Rig/Camera Offset/AR Camera\n  Tag: MainCamera\n  Components: Camera, ARCameraManager, ARCameraBackground, TrackedPoseDriver, AROcclusionManager, ARCameraTextureProvider, AudioListener\n  ARCameraTextureProvider: Converts iOS YCbCr to RGB for ColorMap\n\n### Hologram System\n- Hologram (ID: 128402) - Parent container\n  Path: /Hologram\n  Components: HologramPlacer, HologramController, VideoPlayer, MetadataDecoder, TextureDemuxer\n  \n- HologramVFX (ID: 129162) - VFX renderer\n  Path: Hologram/HologramVFX\n  Scale: 0.15\n  Components: VisualEffect, VFXARBinder, VFXCategory\n  VFXARBinder bindings: ColorMap, PositionMap, DepthMap, RayParams (all enabled)\n\n## Key Scripts\n1. Assets/Scripts/Bridges/ARDepthSource.cs - Singleton, ONE compute dispatch\n2. Assets/Scripts/Bridges/VFXARBinder.cs - Per-VFX lightweight binding\n3. Assets/Shaders/HiFiHologramVFX.hlsl - HLSL for PositionMap+ColorMap sampling\n4. Assets/Scripts/Editor/RealisticHologramSetup.cs - One-click RGB hologram setup\n5. Assets/Scripts/Editor/HiFiHologramVFXCreator.cs - HiFi hologram VFX creation\n\n## Architecture Pattern\nHybrid Bridge: ARDepthSource (O(1) compute) \u2192 VFXARBinder (O(N) SetTexture)\n- Avoids redundant depth\u2192position computation\n- 353 FPS verified with 10 active VFX\n- PositionMap precomputed by GPU, VFX reads directly\n\n## VFX Property Names\nDepthMap, StencilMap, PositionMap, ColorMap, VelocityMap\nRayParams (Vector4), InverseView (Matrix4x4)\nMapWidth, MapHeight (float), Dimensions (Vector2)", "Session 0c6f0f1d-82d8-4a87-8868-760863abe0bc: Fixed VFXToggleUI.cs NullReferenceException at line 837 where UpdateCategoryHeader was called before UI initialization. Added null check for _categoriesContainer. The error occurred due to Start() callback ordering - VFXLibraryManager fired OnVFXToggled callback before VFXToggleUI had initialized its container. Compilation verified clean with no errors. HoloKit EntryPointNotFoundException is expected on macOS (iOS native plugin). Project: Unity-XR-AI/MetavidoVFX.", "WarpJobs Session 2026-02-05: Simplified scoring + interview calendar system\n\nACCOMPLISHED:\n1. Simplified scoring from complex multi-factor to 5-tier system (T1-T5 based on hire probability)\n   - T1 (1000+): Interviews/responses, T2 (200): Core+Senior+Dream, T3 (100): Core+Senior, T4 (50): Adjacent+Senior, T5 (25): Engineering@Dream\n   - Reduced 128 lines to 70 lines, easier to debug/improve\n   - Word-boundary regex for short terms (ar, vr, xr) prevents false positives\n\n2. Added interview calendar system (lib/interview-calendar.js)\n   - Auto-creates Calendar.app events with full context (meeting link, job post, interviewer)\n   - Adds 5 native alarms: 1 day, 6h, 1h, 15min before, at time\n   - Generates action items: LinkedIn connect, company research, role prep, questions\n   - BEST PRACTICE: Uses Calendar.app native alarms NOT LaunchAgents (no daemon proliferation, syncs via iCloud)\n\n3. Protected personal data from GitHub commits\n   - Updated .gitignore: scheduled-interviews.json, immediate-actions.json, linkedin-opportunities.json, key-people.json, relationship-graph.json, vc-portfolio-report.json\n\n4. Updated project docs (CLAUDE.md) with new systems\n\nKEY LEARNING: For macOS reminders, use Calendar.app native alarms via AppleScript instead of creating individual LaunchAgent plists - Calendar handles lifecycle, syncs to all devices via iCloud, no cleanup needed.\n\nFILES MODIFIED: enhanced-intelligence.js, lib/interview-calendar.js (new), lib/self-improve.js, .gitignore, CLAUDE.md\n\nCOMMITS: 6 commits pushed to master (545ef8e through 05fa519)", "MetavidoVFX Session 2026-02-06: VFX Audit & Memory System Simplification\n\nVFX AUDIT COMPLETE:\n- Deep audit of 4 keijiro VFX source projects (Metavido, Rcam2/3/4, Akvfx)\n- Verified our Hybrid Bridge Pattern is architecturally BETTER than keijiro's original\n- 270+ property aliases for cross-project VFX compatibility\n- O(1) compute + O(N) binding = 353 FPS @ 10 VFX\n- ColorMap sampling at same UV as PositionMap = lifelike RGB hologram (device test pending)\n\nMEMORY SYSTEM SIMPLIFIED:\n- Removed broken Stop hook (SDK sessions stopped working Jan 20)\n- Removed claude-mem UserPromptSubmit hook (adds latency, wasn't working)\n- Kept SessionStart hook (loads context on startup - works)\n- Kept MCP tools for manual /save and /remember\n- Exported all 25 memories to KnowledgeBase/_CLAUDE_MEM_ARCHIVE_2026-01.md\n\nKEY INSIGHT - Memory Best Practice:\n- Auto-save broke silently and went unnoticed for 17 days\n- Built-in alternatives (--resume, LEARNING_LOG, KB files) work fine\n- Simpler = more reliable: manual /save + auto-load on start\n\nFiles: ~/.claude/settings.json (hooks simplified), KnowledgeBase/_CLAUDE_MEM_ARCHIVE_2026-01.md (created)", "SESSION PERSISTENCE RULE (2026-02-06): MANDATORY checkpoints every 15-30 min. Save BEFORE /clear or /compact. Checkpoint must include: 1) Summary of accomplishments, 2) Current state (file, line, task), 3) Next steps for resume, 4) Key decisions made, 5) Open questions. Resume with: claude --continue OR claude --resume <name>. FAILURE if context lost between sessions. Rule added to ~/GLOBAL_RULES.md section 'Session Persistence'.", "XRAI Spec KB Search Results (2026-02-12)\n\nSearched kb_knowledge Chroma collection (8302 chunks) for content relevant to the XRAI Specification & Architectural Plan: holographic HUD, AI orchestration (Gemini voice/TTS/thinking), collaborative telepresence (WebRTC P2P), camera segmentation (YOLO mode), audio-reactive shaders, agentic coding swarm, GDrive/GitHub persistence.\n\n6 semantic queries executed. Results organized by domain:\n\nPORTALS ARCHITECTURE & VISION:\n- _PORTALS_V4_STRATEGIC_ROADMAP.md \u2014 Core: vibe coder for spatial creation, voice+gesture+AI, collaborative, Phase 4 collaborative suite\n- _PORTALS_V4_ARCHITECTURE_CRITIQUE.md \u2014 Three product directions: Vibe Coder (A), Video-to-Magic (B), Telepresence (C). Recommends Product A focus.\n- _PORTALS_BRAND_MESSAGING.md \u2014 'Zero-latency vibe world creator, collaborative creativity becomes telepresence'\n- _PORTALS_SIMPLIFIED_PLAN.md \u2014 Holographic Zoom pitch, selfie hologram, live stream modes\n- _PORTALS_FUTUREPROOF_STRATEGY_2026.md \u2014 PeerJS signaling, WebRTC, LiveKit for >4 users\n- _ADVANCED_AR_FEATURES_IMPLEMENTATION_PLAN.md \u2014 12 feature integrations, 7825 lines, XRAI 5D conclusion\n\nXRAI FORMAT & SPATIAL INTELLIGENCE:\n- _XR_SCENE_FORMAT_COMPARISON.md \u2014 .tilt vs USDZ vs glTF vs XRRAI format comparison\n- _HCI_SPATIAL_DESIGN_PRINCIPLES.md \u2014 Design for human cognition first, spatial memory, attention\n- _VFX25_HOLOGRAM_PORTAL_PATTERNS.md \u2014 15+ Keijiro projects, hologram/depth/portal VFX\n- _XRAI_MASTER.md \u2014 XRAI v2.0 glTF-based spec, generative encoding, compression\n\nAI ORCHESTRATION & VOICE:\n- _FIGMENTAR_UNITY_REUSE_ANALYSIS.md \u2014 KEY: voice (Gemini) vs audio-reactive (VFX) dual pipeline, phase 1-5\n- _UNIFIED_AUDIO_REACTIVE_PATTERNS.md \u2014 Single FFT pipeline, 8-band frequency, XRRAI.Audio.UnifiedAudioReactive\n- _PORTALS_V4_STRATEGIC_ROADMAP.md \u2014 Spec 006: AudioBridge singleton, 4 frequency bands, beat detection\n- _CROSS_TOOL_SESSION_INSIGHTS.md \u2014 Gemini CLI session insights on voice-AI bridge\n- _LASPVFX_AUDIO_BINDING_PATTERNS.md \u2014 Web Audio API, waveform oscillators, pitch detection\n\nAGENTIC CODING SWARM:\n- _ACE_CONTEXT_ENGINEERING_PATTERNS.md \u2014 300k LOC with agent teams, version-control prompts\n- AgentSystems/Realtime_API_Agents_Demo.md \u2014 OpenAI Swarm: voice -> specialized agents -> handoff\n- _AI_CODING_BEST_PRACTICES.md \u2014 Unity MCP tools, vibe coding links\n\nWEBRTC TELEPRESENCE & PERSISTENCE:\n- _WEBRTC_MULTIUSER_MULTIPLATFORM_GUIDE.md \u2014 Photon/Normcore/coherence comparison\n- _H3M_HOLOGRAM_ROADMAP.md \u2014 Phase 2: WebRTC RGBD + audio P2P\n- _HOLOGRAM_MASTER.md \u2014 Spec 003 streaming, Layer 6 multi-user\n- _COMPREHENSIVE_HOLOGRAM_PIPELINE_ARCHITECTURE.md \u2014 6-layer hologram architecture\n- _WEB_MASTER.md \u2014 XRAI/VNMF specs, Normcore multiplayer, neural field portals\n\nCAMERA SEGMENTATION / YOLO MODE:\n- _UNITY_ML_MASTER.md \u2014 ARDepthSource -> BodyPartSegmenter -> YOLO pipeline\n- _UNITY_SENTIS_ONNX_MOBILE_XR_RESEARCH_2026.md \u2014 BodyPix 30-60fps, YOLOv8-seg 5fps Quest\n- _ML_RESEARCH_MASTER.md \u2014 COCO 80-class mask, bounding boxes, AR overlay\n- _ONNXRUNTIME_UNITY_EXAMPLES.md \u2014 Real-time person segmentation + VFX spawning\n\nTOP 10 FILES FOR XRAI SPEC:\n1. _PORTALS_V4_STRATEGIC_ROADMAP.md\n2. _PORTALS_V4_ARCHITECTURE_CRITIQUE.md\n3. _FIGMENTAR_UNITY_REUSE_ANALYSIS.md\n4. _ADVANCED_AR_FEATURES_IMPLEMENTATION_PLAN.md\n5. _HOLOGRAM_MASTER.md\n6. _WEBRTC_MULTIUSER_MULTIPLATFORM_GUIDE.md\n7. _UNIFIED_AUDIO_REACTIVE_PATTERNS.md\n8. _HCI_SPATIAL_DESIGN_PRINCIPLES.md\n9. _UNITY_ML_MASTER.md\n10. _ACE_CONTEXT_ENGINEERING_PATTERNS.md"], "metadatas": [{"session_date": "2026-01-16", "tags": "unity,xr,ar,vfx,knowledgebase", "project": "Unity-XR-AI", "type": "session_overview"}, {"date": "2026-01-16", "type": "architecture", "tags": "vfx,pipeline,hybrid-bridge,ARDepthSource,VFXARBinder", "project": "MetavidoVFX", "priority": "high"}, {"project": "MetavidoVFX", "type": "workflow", "tags": "testing,debugging,verbose-logging,mcp,unity", "priority": "high", "date": "2026-01-16"}, {"project": "MetavidoVFX", "type": "platform-compatibility", "date": "2026-01-16", "tags": "WebGL,VFX,react-unity,compute-shaders"}, {"category": "vfx-limitation", "verified": true, "date": "2026-01-16", "project": "MetavidoVFX"}, {"category": "csharp-pattern", "project": "MetavidoVFX", "error_code": "CS0206", "date": "2026-01-16"}, {"category": "architecture-pattern", "recommended": true, "project": "MetavidoVFX", "date": "2026-01-16"}, {"project": "MetavidoVFX", "category": "platform-limitation", "verified": true, "date": "2026-01-16"}, {"category": "debug-pattern", "date": "2026-01-16", "project": "MetavidoVFX"}, {"project": "MetavidoVFX", "category": "testing-pattern", "date": "2026-01-16"}, {"tags": "global_rules,session_start,file_safety,never_delete", "priority": "highest", "type": "critical_rule", "user": "james", "project": "all_projects", "created": "2026-01-16"}, {"tags": "never_delete,file_safety,critical_rule,all_projects", "user": "james", "created": "2026-01-16", "rule_type": "file_safety", "priority": "critical", "type": "user_rule"}, {"project": "global", "priority": "high", "type": "startup-task", "date": "2026-01-19", "topic": "mcp-servers"}, {"priority": "critical", "type": "preference", "project": "global", "topic": "token-optimization", "date": "2026-01-19"}, {"tags": "ARFoundation,BugFix,TryGetTexture,iOS,Unity,NullReferenceException", "project": "MetavidoVFX", "date": "2026-01-20", "type": "session_summary"}, {"session_date": "2026-01-20", "date": "2026-01-20", "spec": "007", "title": "VFX Multi-Mode Implementation", "project": "Unity-XR-AI", "phases": "1-3", "concepts": "VFXModeController,BeatDetector,spectral-flux,demand-driven-loading", "status": "complete", "type": "overview"}, {"project": "Unity-XR-AI", "priority": "critical", "created": "2026-01-20", "tags": "mcp,performance,startup,claude-code", "type": "startup_task"}, {"topic": "NNCam VFX", "date": "2026-01-20", "project": "MetavidoVFX", "type": "solution"}, {"project": "Unity-XR-AI", "type": "architecture", "created": "2026-01-20"}, {"type": "codebase", "project": "MetavidoVFX", "created": "2026-01-20"}, {"created": "2026-01-20", "type": "tooling", "project": "Unity-XR-AI"}, {"project": "MetavidoVFX", "date": "2026-01-21", "type": "session-learnings", "tags": "hologram,vfx,hifi,positionmap,colormap,architecture"}, {"project": "MetavidoVFX", "date": "2026-01-21", "scene": "HOLOGRAM.unity", "type": "scene-structure", "tags": "scene,hologram,ar,vfx,architecture,cross-tool"}, {"session_id": "0c6f0f1d-82d8-4a87-8868-760863abe0bc", "project": "Unity-XR-AI", "date": "2026-01-22", "tags": "bugfix,unity,vfx,race-condition", "type": "session_overview", "fix": "VFXToggleUI null check"}, {"tags": "scoring,calendar,interview,simplification,best-practice", "type": "session-summary", "project": "WarpJobs", "files": "enhanced-intelligence.js,lib/interview-calendar.js,lib/self-improve.js,.gitignore,CLAUDE.md", "date": "2026-02-05"}, {"tags": "vfx-audit,memory-system,hybrid-bridge,simplification", "date": "2026-02-06", "type": "session-summary", "project": "Unity-XR-AI"}, {"type": "mandatory-rule", "project": "global-rules", "date": "2026-02-06", "importance": "critical"}, {"date": "2026-02-12", "type": "research", "priority": "high", "project": "XRAI", "tags": "xrai,portals,hologram,hud,telepresence,webrtc,gemini,voice,audio-reactive,shader,yolo,segmentation,agentic,swarm,vibe-coding,collaborative"}]}
